"use strict";(globalThis.webpackChunk=globalThis.webpackChunk||[]).push([[4088],{8418:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"modules/module-3-ai-robot-brain/integrated-applications","title":"Integrated Applications","description":"How Isaac Sim, Isaac ROS, and Nav2 work together in integrated humanoid robot applications for autonomous navigation.","source":"@site/docs/modules/module-3-ai-robot-brain/integrated-applications.md","sourceDirName":"modules/module-3-ai-robot-brain","slug":"/modules/module-3-ai-robot-brain/integrated-applications","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/integrated-applications","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"integrated-applications","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/integrated-applications"},{"inline":true,"label":"workflow","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/workflow"},{"inline":true,"label":"training","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/training"},{"inline":true,"label":"perception","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/perception"},{"inline":true,"label":"planning","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/planning"},{"inline":true,"label":"autonomous-navigation","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/autonomous-navigation"}],"version":"current","sidebarPosition":6,"frontMatter":{"id":"integrated-applications","title":"Integrated Applications","sidebar_position":6,"description":"How Isaac Sim, Isaac ROS, and Nav2 work together in integrated humanoid robot applications for autonomous navigation.","tags":["integrated-applications","workflow","training","perception","planning","autonomous-navigation"],"learning_objectives":["lo-010"]},"sidebar":"textbookSidebar","previous":{"title":"Nav2 - Bipedal Humanoid Path Planning","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/nav2-path-planning"},"next":{"title":"Glossary","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/glossary"}}');var o=i(4848),t=i(8453);const s={id:"integrated-applications",title:"Integrated Applications",sidebar_position:6,description:"How Isaac Sim, Isaac ROS, and Nav2 work together in integrated humanoid robot applications for autonomous navigation.",tags:["integrated-applications","workflow","training","perception","planning","autonomous-navigation"],learning_objectives:["lo-010"]},r="Integrated Applications: The Complete AI-Robot Brain Workflow",l={},c=[{value:"The Complete Workflow",id:"the-complete-workflow",level:2},{value:"Training Phase: Learning from Simulation",id:"training-phase-learning-from-simulation",level:3},{value:"Perception Phase: Understanding in Real-Time",id:"perception-phase-understanding-in-real-time",level:3},{value:"Planning Phase: Computing Safe Paths",id:"planning-phase-computing-safe-paths",level:3},{value:"Navigation: Autonomous Movement",id:"navigation-autonomous-movement",level:3},{value:"Practical Application Scenario",id:"practical-application-scenario",level:2},{value:"Scenario Setup",id:"scenario-setup",level:3},{value:"Complete Workflow",id:"complete-workflow",level:3},{value:"1. Pre-Deployment: Training (Isaac Sim)",id:"1-pre-deployment-training-isaac-sim",level:4},{value:"2. Deployment: Perception (Isaac ROS)",id:"2-deployment-perception-isaac-ros",level:4},{value:"3. Navigation: Planning (Nav2)",id:"3-navigation-planning-nav2",level:4},{value:"4. Continuous Operation",id:"4-continuous-operation",level:4},{value:"How Perception Informs Planning",id:"how-perception-informs-planning",level:2},{value:"Map Data Flow",id:"map-data-flow",level:3},{value:"Robot Localization",id:"robot-localization",level:3},{value:"Dynamic Obstacle Detection",id:"dynamic-obstacle-detection",level:3},{value:"How Training Supports Perception",id:"how-training-supports-perception",level:2},{value:"Algorithm Transfer",id:"algorithm-transfer",level:3},{value:"Domain Adaptation",id:"domain-adaptation",level:3},{value:"The Integrated System",id:"the-integrated-system",level:2},{value:"System Characteristics",id:"system-characteristics",level:3},{value:"Real-World Value",id:"real-world-value",level:2},{value:"Autonomous Operation",id:"autonomous-operation",level:3},{value:"Efficient Development",id:"efficient-development",level:3},{value:"Scalable Deployment",id:"scalable-deployment",level:3},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"integrated-applications-the-complete-ai-robot-brain-workflow",children:"Integrated Applications: The Complete AI-Robot Brain Workflow"})}),"\n",(0,o.jsxs)(e.p,{children:["Understanding individual tools is important, but the real power of the AI-robot brain comes from how ",(0,o.jsx)(e.strong,{children:"Isaac Sim, Isaac ROS, and Nav2 work together"})," as an integrated system. This section demonstrates the complete workflow: from training perception algorithms in simulation to real-time navigation in physical environments."]}),"\n",(0,o.jsx)(e.h2,{id:"the-complete-workflow",children:"The Complete Workflow"}),"\n",(0,o.jsx)(e.p,{children:"The AI-robot brain workflow follows a clear progression:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"Training (Isaac Sim) \u2192 Perception (Isaac ROS) \u2192 Planning (Nav2) \u2192 Navigation\n"})}),"\n",(0,o.jsx)(e.p,{children:"Each component builds upon the previous one, creating a complete system for autonomous humanoid robot navigation."}),"\n",(0,o.jsx)(e.h3,{id:"training-phase-learning-from-simulation",children:"Training Phase: Learning from Simulation"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"NVIDIA Isaac Sim"})," generates synthetic training data:"]}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Create photorealistic virtual environments"}),"\n",(0,o.jsx)(e.li,{children:"Render images with realistic lighting and materials"}),"\n",(0,o.jsx)(e.li,{children:"Generate ground truth labels automatically"}),"\n",(0,o.jsx)(e.li,{children:"Create diverse training datasets with variations"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Output"}),": Trained perception algorithms that understand visual information"]}),"\n",(0,o.jsx)(e.h3,{id:"perception-phase-understanding-in-real-time",children:"Perception Phase: Understanding in Real-Time"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Isaac ROS"})," deploys trained algorithms for real-time perception:"]}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Process camera images using trained algorithms"}),"\n",(0,o.jsx)(e.li,{children:"Extract visual features and track movement"}),"\n",(0,o.jsx)(e.li,{children:"Build environment maps"}),"\n",(0,o.jsx)(e.li,{children:"Localize robot position within maps"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Output"}),": Real-time environmental understanding and robot localization"]}),"\n",(0,o.jsx)(e.h3,{id:"planning-phase-computing-safe-paths",children:"Planning Phase: Computing Safe Paths"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Nav2"})," uses perception data for path planning:"]}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Access environment maps from perception"}),"\n",(0,o.jsx)(e.li,{children:"Consider humanoid constraints (balance, foot placement)"}),"\n",(0,o.jsx)(e.li,{children:"Compute safe paths to goal locations"}),"\n",(0,o.jsx)(e.li,{children:"Generate step sequences for bipedal movement"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Output"}),": Safe, executable movement paths"]}),"\n",(0,o.jsx)(e.h3,{id:"navigation-autonomous-movement",children:"Navigation: Autonomous Movement"}),"\n",(0,o.jsx)(e.p,{children:"The robot executes planned paths while continuously:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Updating perception based on new visual information"}),"\n",(0,o.jsx)(e.li,{children:"Replanning paths as environment changes"}),"\n",(0,o.jsx)(e.li,{children:"Adapting to dynamic obstacles and terrain"}),"\n",(0,o.jsx)(e.li,{children:"Maintaining balance and stability throughout movement"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Output"}),": Autonomous navigation through complex environments"]}),"\n",(0,o.jsx)(e.h2,{id:"practical-application-scenario",children:"Practical Application Scenario"}),"\n",(0,o.jsx)(e.p,{children:"Consider a humanoid robot navigating through an indoor office environment to reach a specific room:"}),"\n",(0,o.jsx)(e.h3,{id:"scenario-setup",children:"Scenario Setup"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Goal"}),": Navigate from office entrance to conference room"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Environment"}),": Indoor office with corridors, rooms, furniture, people"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Challenges"}),": Dynamic obstacles (people moving), narrow passages, changing lighting"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"complete-workflow",children:"Complete Workflow"}),"\n",(0,o.jsx)(e.h4,{id:"1-pre-deployment-training-isaac-sim",children:"1. Pre-Deployment: Training (Isaac Sim)"}),"\n",(0,o.jsx)(e.p,{children:"Before the robot is deployed, perception algorithms are trained:"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Training Process"}),":"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Isaac Sim generates thousands of synthetic images of indoor office environments"}),"\n",(0,o.jsx)(e.li,{children:"Images include variations: different lighting, furniture arrangements, people, obstacles"}),"\n",(0,o.jsx)(e.li,{children:"Algorithms learn to recognize: walls, doors, furniture, people, walkable floors"}),"\n",(0,o.jsx)(e.li,{children:"Training produces algorithms that understand indoor office environments"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Result"}),": Perception algorithms ready for deployment"]}),"\n",(0,o.jsx)(e.h4,{id:"2-deployment-perception-isaac-ros",children:"2. Deployment: Perception (Isaac ROS)"}),"\n",(0,o.jsx)(e.p,{children:"When the robot operates, Isaac ROS processes real-world visual data:"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Real-Time Perception"}),":"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Robot's cameras capture images of the office environment"}),"\n",(0,o.jsx)(e.li,{children:"Isaac ROS processes images using trained algorithms"}),"\n",(0,o.jsx)(e.li,{children:"VSLAM builds a map of the office as the robot moves"}),"\n",(0,o.jsx)(e.li,{children:"Robot continuously localizes itself within the map"}),"\n",(0,o.jsx)(e.li,{children:"Dynamic obstacles (people) are detected and tracked"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Result"}),": Real-time understanding of current environment and robot position"]}),"\n",(0,o.jsx)(e.h4,{id:"3-navigation-planning-nav2",children:"3. Navigation: Planning (Nav2)"}),"\n",(0,o.jsx)(e.p,{children:"Nav2 uses perception data to plan movement:"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Path Planning"}),":"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Navigation goal: reach conference room"}),"\n",(0,o.jsx)(e.li,{children:"Nav2 accesses office map from perception system"}),"\n",(0,o.jsx)(e.li,{children:"Considers humanoid constraints: balance, foot placement, step size"}),"\n",(0,o.jsx)(e.li,{children:"Computes path avoiding obstacles and maintaining stability"}),"\n",(0,o.jsx)(e.li,{children:"Generates sequence of foot placements for bipedal movement"}),"\n",(0,o.jsx)(e.li,{children:"Continuously replans as environment changes (people move, doors open/close)"}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Result"}),": Safe, executable path to goal location"]}),"\n",(0,o.jsx)(e.h4,{id:"4-continuous-operation",children:"4. Continuous Operation"}),"\n",(0,o.jsx)(e.p,{children:"The system runs continuously:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Perception updates"}),": New camera images update map and robot position"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Path replanning"}),": Nav2 adjusts path based on latest perception data"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Balance maintenance"}),": Robot maintains stability while following path"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Goal achievement"}),": Robot reaches conference room autonomously"]}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Result"}),": Successful autonomous navigation through complex environment"]}),"\n",(0,o.jsx)(e.h2,{id:"how-perception-informs-planning",children:"How Perception Informs Planning"}),"\n",(0,o.jsx)(e.p,{children:"The integration between perception (Isaac ROS) and planning (Nav2) is critical:"}),"\n",(0,o.jsx)(e.h3,{id:"map-data-flow",children:"Map Data Flow"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Perception \u2192 Planning"}),":"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Isaac ROS builds environment map through VSLAM"}),"\n",(0,o.jsx)(e.li,{children:"Nav2 accesses this map to understand obstacle locations"}),"\n",(0,o.jsx)(e.li,{children:"Map updates as robot explores new areas"}),"\n",(0,o.jsx)(e.li,{children:"Planning adapts to map changes in real-time"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"robot-localization",children:"Robot Localization"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Perception \u2192 Planning"}),":"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Isaac ROS determines robot's current position"}),"\n",(0,o.jsx)(e.li,{children:"Nav2 uses this position as starting point for path planning"}),"\n",(0,o.jsx)(e.li,{children:"Continuous localization updates enable accurate path execution"}),"\n",(0,o.jsx)(e.li,{children:"Planning adjusts when localization detects robot has deviated from expected path"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"dynamic-obstacle-detection",children:"Dynamic Obstacle Detection"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Perception \u2192 Planning"}),":"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Isaac ROS detects moving obstacles (people, objects)"}),"\n",(0,o.jsx)(e.li,{children:"Nav2 receives obstacle updates in real-time"}),"\n",(0,o.jsx)(e.li,{children:"Planning recomputes paths to avoid dynamic obstacles"}),"\n",(0,o.jsx)(e.li,{children:"Enables safe navigation in dynamic environments"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"This perception \u2192 planning integration enables responsive, adaptive navigation that reacts to changing environments."}),"\n",(0,o.jsx)(e.h2,{id:"how-training-supports-perception",children:"How Training Supports Perception"}),"\n",(0,o.jsx)(e.p,{children:"The connection between training (Isaac Sim) and perception (Isaac ROS) enables real-world deployment:"}),"\n",(0,o.jsx)(e.h3,{id:"algorithm-transfer",children:"Algorithm Transfer"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Training \u2192 Perception"}),":"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Algorithms trained on synthetic data from Isaac Sim"}),"\n",(0,o.jsx)(e.li,{children:"Same algorithms deployed in real robot via Isaac ROS"}),"\n",(0,o.jsx)(e.li,{children:"Training data variations help algorithms generalize to real-world conditions"}),"\n",(0,o.jsx)(e.li,{children:"Hardware acceleration enables real-time operation of trained algorithms"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"domain-adaptation",children:"Domain Adaptation"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Training \u2192 Perception"}),":"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Synthetic training includes diverse scenarios (lighting, environments, objects)"}),"\n",(0,o.jsx)(e.li,{children:"Real-world perception encounters similar scenarios"}),"\n",(0,o.jsx)(e.li,{children:"Trained algorithms recognize real-world features learned from synthetic data"}),"\n",(0,o.jsx)(e.li,{children:"Enables perception to work effectively without extensive real-world training data collection"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"This training \u2192 perception connection demonstrates how simulation enables real-world capabilities."}),"\n",(0,o.jsx)(e.h2,{id:"the-integrated-system",children:"The Integrated System"}),"\n",(0,o.jsx)(e.p,{children:"When all three components work together:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-mermaid",children:"graph TB\n    A[Isaac Sim<br/>Training] --\x3e B[Trained<br/>Algorithms]\n    B --\x3e C[Isaac ROS<br/>Perception]\n    C --\x3e D[Environment<br/>Map]\n    C --\x3e E[Robot<br/>Pose]\n    D --\x3e F[Nav2<br/>Planning]\n    E --\x3e F\n    F --\x3e G[Path<br/>Sequence]\n    G --\x3e H[Humanoid<br/>Navigation]\n    \n    I[Camera<br/>Images] --\x3e C\n    J[Dynamic<br/>Obstacles] --\x3e C\n    C --\x3e K[Updated<br/>Map]\n    K --\x3e F\n    \n    style A fill:#e1f5ff\n    style C fill:#fff4e1\n    style F fill:#ffe1f5\n    style H fill:#e1ffe1\n"})}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.em,{children:"Figure: Integrated AI-robot brain workflow showing how training, perception, and planning components work together for autonomous navigation."})}),"\n",(0,o.jsx)(e.h3,{id:"system-characteristics",children:"System Characteristics"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Continuous operation"}),": All components run simultaneously"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Real-time updates"}),": Perception and planning update continuously"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Adaptive behavior"}),": System responds to environmental changes"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Integrated data flow"}),": Information flows seamlessly between components"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"real-world-value",children:"Real-World Value"}),"\n",(0,o.jsx)(e.p,{children:"The integrated AI-robot brain enables:"}),"\n",(0,o.jsx)(e.h3,{id:"autonomous-operation",children:"Autonomous Operation"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Robots navigate without human guidance"}),"\n",(0,o.jsx)(e.li,{children:"Adapt to changing environments automatically"}),"\n",(0,o.jsx)(e.li,{children:"Handle unexpected situations safely"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"efficient-development",children:"Efficient Development"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Training in simulation reduces real-world data collection needs"}),"\n",(0,o.jsx)(e.li,{children:"Hardware acceleration enables real-time performance"}),"\n",(0,o.jsx)(e.li,{children:"Integrated workflow simplifies system development"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"scalable-deployment",children:"Scalable Deployment"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Trained algorithms work across different environments"}),"\n",(0,o.jsx)(e.li,{children:"Perception adapts to new locations"}),"\n",(0,o.jsx)(e.li,{children:"Planning handles various scenarios"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:"The AI-robot brain integrates three components into a complete autonomous navigation system:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Isaac Sim (Training)"}),": Generates synthetic data to train perception algorithms"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Isaac ROS (Perception)"}),": Deploys trained algorithms for real-time environmental understanding"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Nav2 (Planning)"}),": Uses perception data to compute safe paths for humanoid movement"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"Together, these tools enable the complete workflow: training \u2192 perception \u2192 planning \u2192 navigation. This integration demonstrates how modern humanoid robots achieve autonomous capabilities through the coordinated operation of advanced AI tools."}),"\n",(0,o.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsxs)(e.p,{children:["You've now explored all components of the AI-robot brain. Review the ",(0,o.jsx)(e.a,{href:"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/glossary",children:"Glossary"})," for key terminology definitions, or revisit any section to deepen your understanding of how these advanced tools enable autonomous humanoid robot navigation."]})]})}function h(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>s,x:()=>r});var a=i(6540);const o={},t=a.createContext(o);function s(n){const e=a.useContext(t);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),a.createElement(t.Provider,{value:e},n.children)}}}]);