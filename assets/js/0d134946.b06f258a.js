"use strict";(globalThis.webpackChunk=globalThis.webpackChunk||[]).push([[2780],{4728:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"modules/module-1-ros2-nervous-system/humanoid-applications","title":"Humanoid Robotics Applications","description":"Connecting ROS 2 concepts to humanoid robotics applications including sensor integration, actuator coordination, and locomotion control.","source":"@site/docs/modules/module-1-ros2-nervous-system/humanoid-applications.md","sourceDirName":"modules/module-1-ros2-nervous-system","slug":"/modules/module-1-ros2-nervous-system/humanoid-applications","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-1-ros2-nervous-system/humanoid-applications","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"ros2","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/ros-2"},{"inline":true,"label":"humanoid-robotics","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/humanoid-robotics"},{"inline":true,"label":"applications","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/applications"},{"inline":true,"label":"sensors","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/sensors"},{"inline":true,"label":"actuators","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/actuators"},{"inline":true,"label":"locomotion","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/locomotion"}],"version":"current","sidebarPosition":4,"frontMatter":{"id":"humanoid-applications","title":"Humanoid Robotics Applications","sidebar_position":4,"description":"Connecting ROS 2 concepts to humanoid robotics applications including sensor integration, actuator coordination, and locomotion control.","tags":["ros2","humanoid-robotics","applications","sensors","actuators","locomotion"],"learning_objectives":["lo-003"]},"sidebar":"textbookSidebar","previous":{"title":"Communication Patterns","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-1-ros2-nervous-system/communication-patterns"},"next":{"title":"Workspace Overview","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-1-ros2-nervous-system/workspace-overview"}}');var i=o(4848),t=o(8453);const r={id:"humanoid-applications",title:"Humanoid Robotics Applications",sidebar_position:4,description:"Connecting ROS 2 concepts to humanoid robotics applications including sensor integration, actuator coordination, and locomotion control.",tags:["ros2","humanoid-robotics","applications","sensors","actuators","locomotion"],learning_objectives:["lo-003"]},a="Humanoid Robotics Applications",l={},c=[{value:"ROS 2 in Humanoid Robotics",id:"ros-2-in-humanoid-robotics",level:2},{value:"Sensor Integration with Topics",id:"sensor-integration-with-topics",level:2},{value:"Vision Sensors",id:"vision-sensors",level:3},{value:"Proprioceptive Sensors",id:"proprioceptive-sensors",level:3},{value:"Actuator Coordination with Services",id:"actuator-coordination-with-services",level:2},{value:"Coordinated Movement",id:"coordinated-movement",level:3},{value:"Configuration Services",id:"configuration-services",level:3},{value:"Locomotion Control with Actions",id:"locomotion-control-with-actions",level:2},{value:"Walking Action",id:"walking-action",level:3},{value:"Mapping ROS 2 Components to Robot Subsystems",id:"mapping-ros-2-components-to-robot-subsystems",level:2},{value:"Complete System Example",id:"complete-system-example",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"humanoid-robotics-applications",children:"Humanoid Robotics Applications"})}),"\n",(0,i.jsx)(n.p,{children:"Now that you understand ROS 2's core concepts and communication patterns, let's explore how these apply specifically to humanoid robotics. Humanoid robots present unique challenges that make ROS 2's distributed communication architecture particularly valuable."}),"\n",(0,i.jsx)(n.h2,{id:"ros-2-in-humanoid-robotics",children:"ROS 2 in Humanoid Robotics"}),"\n",(0,i.jsx)(n.p,{children:"Humanoid robots are among the most complex robotic systems, requiring coordination between:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Multiple sensors"})," (vision, proprioception, touch, balance)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Numerous actuators"})," (joints in arms, legs, hands, head)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Complex processing"})," (perception, planning, control)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Real-time coordination"})," for stable, natural movement"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"ROS 2's distributed architecture makes it possible to manage this complexity by allowing specialized nodes to handle different aspects of the robot's operation."}),"\n",(0,i.jsx)(n.h2,{id:"sensor-integration-with-topics",children:"Sensor Integration with Topics"}),"\n",(0,i.jsx)(n.p,{children:"Humanoid robots rely on extensive sensor arrays to perceive their environment and understand their own state. ROS 2 topics are ideal for streaming this continuous sensor data."}),"\n",(0,i.jsx)(n.h3,{id:"vision-sensors",children:"Vision Sensors"}),"\n",(0,i.jsx)(n.p,{children:"Humanoid robots typically have multiple cameras (head-mounted, hand-mounted) that generate continuous image streams:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Example: Camera sensor node publishing images\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\n\nclass HeadCameraNode(Node):\n    def __init__(self):\n        super().__init__('head_camera')\n        self.publisher = self.create_publisher(Image, 'sensors/head_camera/image', 10)\n        self.timer = self.create_timer(0.033, self.publish_image)  # 30 FPS\n    \n    def publish_image(self):\n        # Capture image from head-mounted camera\n        msg = Image()\n        # ... populate with camera data ...\n        self.publisher.publish(msg)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Multiple processing nodes can subscribe to these image topics:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Object detection node"})," - Identifies objects in the scene"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Face recognition node"})," - Recognizes human faces"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Navigation node"})," - Uses visual information for localization"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"proprioceptive-sensors",children:"Proprioceptive Sensors"}),"\n",(0,i.jsx)(n.p,{children:"Proprioceptive sensors (joint encoders, IMUs, force sensors) provide continuous feedback about the robot's body state:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Example: Joint state publisher\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState\n\nclass JointStatePublisher(Node):\n    def __init__(self):\n        super().__init__('joint_state_publisher')\n        self.publisher = self.create_publisher(JointState, 'sensors/joint_states', 10)\n        self.timer = self.create_timer(0.01, self.publish_states)  # 100 Hz\n    \n    def publish_states(self):\n        msg = JointState()\n        # Populate with joint positions, velocities, efforts\n        # ... read from robot hardware ...\n        self.publisher.publish(msg)\n"})}),"\n",(0,i.jsx)(n.p,{children:"This joint state information flows to:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Control nodes"})," - For closed-loop control of each joint"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Balance node"})," - For maintaining stability"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Planning node"})," - For motion planning"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"actuator-coordination-with-services",children:"Actuator Coordination with Services"}),"\n",(0,i.jsx)(n.p,{children:"Humanoid robots have many actuators (typically 20-40+ joints) that must be coordinated precisely. Services are useful for on-demand actuator control and configuration."}),"\n",(0,i.jsx)(n.h3,{id:"coordinated-movement",children:"Coordinated Movement"}),"\n",(0,i.jsx)(n.p,{children:"When a humanoid robot needs to perform a coordinated movement (like reaching for an object), multiple joints must move together:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Example: Actuator coordination service\nimport rclpy\nfrom rclpy.node import Node\nfrom example_interfaces.srv import SetBool\n\nclass ArmControlService(Node):\n    def __init__(self):\n        super().__init__('arm_control')\n        self.srv = self.create_service(\n            SetBool,\n            'control/arm/move_to_pose',\n            self.move_arm_callback\n        )\n    \n    def move_arm_callback(self, request, response):\n        if request.data:  # If request is to move\n            # Coordinate multiple joints to reach target pose\n            # Shoulder, elbow, wrist joints move together\n            response.success = self.execute_coordinated_movement()\n            response.message = \"Arm movement executed\" if response.success else \"Movement failed\"\n        return response\n"})}),"\n",(0,i.jsx)(n.h3,{id:"configuration-services",children:"Configuration Services"}),"\n",(0,i.jsx)(n.p,{children:"Services are also useful for configuring actuator parameters:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Example: Setting joint limits or control parameters\nclass JointConfigService(Node):\n    def __init__(self):\n        super().__init__('joint_config')\n        self.srv = self.create_service(\n            # Custom service type for joint configuration\n            'joint_config',\n            self.config_callback\n        )\n    \n    def config_callback(self, request, response):\n        # Set joint speed limits, torque limits, etc.\n        # This is a synchronous operation - we need confirmation\n        response.success = True\n        return response\n"})}),"\n",(0,i.jsx)(n.h2,{id:"locomotion-control-with-actions",children:"Locomotion Control with Actions"}),"\n",(0,i.jsx)(n.p,{children:"Walking and other locomotion behaviors are long-running tasks that require continuous feedback and the ability to adapt or cancel. Actions are perfect for these scenarios."}),"\n",(0,i.jsx)(n.h3,{id:"walking-action",children:"Walking Action"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Example: Walking action for humanoid robot\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.action import ActionServer\n# Custom action type for navigation\nfrom custom_msgs.action import WalkToGoal\n\nclass WalkingActionServer(Node):\n    def __init__(self):\n        super().__init__('walking_server')\n        self._action_server = ActionServer(\n            self,\n            WalkToGoal,\n            'locomotion/walk',\n            self.walk_callback\n        )\n    \n    def walk_callback(self, goal_handle):\n        goal = goal_handle.request\n        feedback_msg = WalkToGoal.Feedback()\n        \n        # Execute walking with continuous feedback\n        total_steps = self.calculate_steps(goal.target_pose)\n        current_step = 0\n        \n        while current_step < total_steps:\n            # Execute one walking step\n            # Update balance, shift weight, lift foot, place foot\n            current_step += 1\n            \n            # Provide feedback\n            feedback_msg.current_step = current_step\n            feedback_msg.total_steps = total_steps\n            feedback_msg.current_pose = self.get_current_pose()\n            goal_handle.publish_feedback(feedback_msg)\n            \n            # Check for cancellation (e.g., obstacle detected)\n            if goal_handle.is_cancel_requested:\n                goal_handle.canceled()\n                return WalkToGoal.Result()\n        \n        # Walking complete\n        goal_handle.succeed()\n        result = WalkToGoal.Result()\n        result.final_pose = self.get_current_pose()\n        return result\n"})}),"\n",(0,i.jsx)(n.p,{children:"This walking action provides:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Continuous feedback"})," on progress (current step, current pose)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Ability to cancel"})," if an obstacle is detected"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Final result"})," with the achieved pose"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"mapping-ros-2-components-to-robot-subsystems",children:"Mapping ROS 2 Components to Robot Subsystems"}),"\n",(0,i.jsx)(n.p,{children:"Here's how ROS 2 components map to a humanoid robot's subsystems:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Robot Subsystem"}),(0,i.jsx)(n.th,{children:"ROS 2 Component"}),(0,i.jsx)(n.th,{children:"Communication Pattern"}),(0,i.jsx)(n.th,{children:"Example"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Vision System"}),(0,i.jsx)(n.td,{children:"Camera nodes"}),(0,i.jsx)(n.td,{children:"Topics"}),(0,i.jsx)(n.td,{children:"Head camera \u2192 Image processing nodes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Proprioception"}),(0,i.jsx)(n.td,{children:"Sensor nodes"}),(0,i.jsx)(n.td,{children:"Topics"}),(0,i.jsx)(n.td,{children:"Joint encoders \u2192 State estimation"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Balance Control"}),(0,i.jsx)(n.td,{children:"Control nodes"}),(0,i.jsx)(n.td,{children:"Topics + Services"}),(0,i.jsx)(n.td,{children:"IMU data (topic) \u2192 Balance service calls"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Arm Control"}),(0,i.jsx)(n.td,{children:"Actuator nodes"}),(0,i.jsx)(n.td,{children:"Services"}),(0,i.jsx)(n.td,{children:"Reach command \u2192 Arm coordination service"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Leg Control"}),(0,i.jsx)(n.td,{children:"Locomotion nodes"}),(0,i.jsx)(n.td,{children:"Actions"}),(0,i.jsx)(n.td,{children:"Walk command \u2192 Walking action"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Planning"}),(0,i.jsx)(n.td,{children:"Planning nodes"}),(0,i.jsx)(n.td,{children:"Topics + Services"}),(0,i.jsx)(n.td,{children:"Sensor data (topics) \u2192 Plan requests (services)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"High-level Control"}),(0,i.jsx)(n.td,{children:"Behavior nodes"}),(0,i.jsx)(n.td,{children:"Actions"}),(0,i.jsx)(n.td,{children:'"Pick up object" \u2192 Manipulation action'})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"complete-system-example",children:"Complete System Example"}),"\n",(0,i.jsx)(n.p,{children:"In a humanoid robot picking up an object:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Vision nodes"})," publish camera images to topics"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Object detection node"})," subscribes to images, publishes object location to a topic"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Planning node"})," subscribes to object location, calls arm control service to plan trajectory"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Arm control service"})," coordinates multiple joints synchronously"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Grasping action"})," executes the grasp with feedback on finger positions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Balance node"})," continuously subscribes to IMU data (topic) to maintain stability"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"This demonstrates how all three communication patterns work together in a real humanoid robot application."}),"\n",(0,i.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Topics"})," stream continuous sensor data to multiple processing nodes"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Services"})," coordinate actuators for synchronous, on-demand actions"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Actions"})," execute complex behaviors like walking with feedback and cancellation"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Humanoid robots"})," use all three patterns simultaneously for different subsystems"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"ROS 2's distributed architecture"})," makes it possible to manage the complexity of humanoid systems"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.p,{children:["Now that you understand how ROS 2 applies to humanoid robotics, proceed to ",(0,i.jsx)(n.a,{href:"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-1-ros2-nervous-system/workspace-overview",children:"Workspace Overview"})," to learn about ROS 2 workspace structure, or review the ",(0,i.jsx)(n.a,{href:"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-1-ros2-nervous-system/glossary",children:"Glossary"})," for quick reference to key terms."]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>r,x:()=>a});var s=o(6540);const i={},t=s.createContext(i);function r(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);