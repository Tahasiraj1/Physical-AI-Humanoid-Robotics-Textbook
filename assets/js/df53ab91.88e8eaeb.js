"use strict";(globalThis.webpackChunk=globalThis.webpackChunk||[]).push([[9818],{8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>r});var a=i(6540);const o={},t=a.createContext(o);function s(e){const n=a.useContext(t);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),a.createElement(t.Provider,{value:n},e.children)}},9959:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"modules/module-3-ai-robot-brain/glossary","title":"Glossary","description":"Key terminology and definitions for Module 3 - The AI-Robot Brain (NVIDIA Isaac\u2122)","source":"@site/docs/modules/module-3-ai-robot-brain/glossary.md","sourceDirName":"modules/module-3-ai-robot-brain","slug":"/modules/module-3-ai-robot-brain/glossary","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/glossary","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"glossary","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/glossary"},{"inline":true,"label":"terminology","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/terminology"},{"inline":true,"label":"definitions","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/definitions"}],"version":"current","sidebarPosition":7,"frontMatter":{"id":"glossary","title":"Glossary","sidebar_position":7,"description":"Key terminology and definitions for Module 3 - The AI-Robot Brain (NVIDIA Isaac\u2122)","tags":["glossary","terminology","definitions"]},"sidebar":"textbookSidebar","previous":{"title":"Integrated Applications","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/integrated-applications"},"next":{"title":"Module 4 - Vision-Language-Action (VLA)","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/"}}');var o=i(4848),t=i(8453);const s={id:"glossary",title:"Glossary",sidebar_position:7,description:"Key terminology and definitions for Module 3 - The AI-Robot Brain (NVIDIA Isaac\u2122)",tags:["glossary","terminology","definitions"]},r="Glossary",l={},d=[{value:"B",id:"b",level:2},{value:"Bipedal Movement Constraints",id:"bipedal-movement-constraints",level:3},{value:"H",id:"h",level:2},{value:"Hardware Acceleration",id:"hardware-acceleration",level:3},{value:"Humanoid Navigation",id:"humanoid-navigation",level:3},{value:"N",id:"n",level:2},{value:"Nav2 (Navigation2)",id:"nav2-navigation2",level:3},{value:"P",id:"p",level:2},{value:"Path Planning",id:"path-planning",level:3},{value:"Photorealistic Simulation",id:"photorealistic-simulation",level:3},{value:"R",id:"r",level:2},{value:"Real-Time Navigation",id:"real-time-navigation",level:3},{value:"S",id:"s",level:2},{value:"Synthetic Training Data",id:"synthetic-training-data",level:3},{value:"V",id:"v",level:2},{value:"Visual SLAM (VSLAM)",id:"visual-slam-vslam",level:3},{value:"Key Tool Definitions",id:"key-tool-definitions",level:2},{value:"Isaac ROS",id:"isaac-ros",level:3},{value:"NVIDIA Isaac Sim",id:"nvidia-isaac-sim",level:3}];function c(e){const n={a:"a",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",p:"p",strong:"strong",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"glossary",children:"Glossary"})}),"\n",(0,o.jsx)(n.p,{children:"This glossary defines key terms used throughout Module 3. Terms are defined on first use in the module content, and this glossary serves as a reference for quick lookup."}),"\n",(0,o.jsx)(n.h2,{id:"b",children:"B"}),"\n",(0,o.jsx)(n.h3,{id:"bipedal-movement-constraints",children:"Bipedal Movement Constraints"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Definition"}),": Limitations and requirements specific to two-legged humanoid movement that affect path planning and navigation. These constraints include balance requirements (center of mass must stay within support polygon), foot placement constraints (each step must land on flat, stable surfaces), terrain adaptation needs (maximum slope limits, surface detection), and stability considerations (maintaining balance throughout movement)."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Context"}),": Used in humanoid robotics to understand why path planning for bipedal robots differs from wheeled robots."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Related"}),": ",(0,o.jsx)(n.a,{href:"#path-planning",children:"Path Planning"}),", ",(0,o.jsx)(n.a,{href:"#humanoid-navigation",children:"Humanoid Navigation"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Module Reference"}),": See ",(0,o.jsx)(n.a,{href:"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/nav2-path-planning",children:"Nav2 Path Planning section"})," for detailed explanation."]}),"\n",(0,o.jsx)(n.h2,{id:"h",children:"H"}),"\n",(0,o.jsx)(n.h3,{id:"hardware-acceleration",children:"Hardware Acceleration"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Definition"}),": Computation performed on specialized hardware (GPUs) instead of general-purpose processors (CPUs) to achieve improved performance. Hardware acceleration enables parallel processing that dramatically speeds up computationally intensive tasks like image processing and perception algorithms."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Context"}),": Essential for enabling real-time VSLAM and perception processing in humanoid robots."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Related"}),": ",(0,o.jsx)(n.a,{href:"#visual-slam-vslam",children:"Visual SLAM (VSLAM)"}),", ",(0,o.jsx)(n.a,{href:"#real-time-navigation",children:"Real-Time Navigation"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Module Reference"}),": See ",(0,o.jsx)(n.a,{href:"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/isaac-ros",children:"Isaac ROS section"})," for detailed explanation."]}),"\n",(0,o.jsx)(n.h3,{id:"humanoid-navigation",children:"Humanoid Navigation"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Definition"}),": The process of humanoid robots moving through environments autonomously, accounting for bipedal movement constraints such as balance, foot placement, and terrain adaptation. Humanoid navigation requires path planning that differs from wheeled robots due to the need for discrete foot placements and balance maintenance."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Context"}),": The goal of integrating perception and planning systems for autonomous humanoid robots."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Related"}),": ",(0,o.jsx)(n.a,{href:"#path-planning",children:"Path Planning"}),", ",(0,o.jsx)(n.a,{href:"#bipedal-movement-constraints",children:"Bipedal Movement Constraints"})]}),"\n",(0,o.jsx)(n.h2,{id:"n",children:"N"}),"\n",(0,o.jsx)(n.h3,{id:"nav2-navigation2",children:"Nav2 (Navigation2)"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Definition"}),": A ROS 2 navigation framework that provides path planning, obstacle avoidance, and navigation capabilities. Nav2 includes adaptations for bipedal humanoid robots that account for balance requirements, foot placement constraints, and terrain adaptation needs."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Context"}),": Used for path planning in humanoid robots, computing safe and efficient routes that account for humanoid-specific movement constraints."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Related"}),": ",(0,o.jsx)(n.a,{href:"#path-planning",children:"Path Planning"}),", ",(0,o.jsx)(n.a,{href:"#bipedal-movement-constraints",children:"Bipedal Movement Constraints"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Module Reference"}),": See ",(0,o.jsx)(n.a,{href:"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/nav2-path-planning",children:"Nav2 Path Planning section"})," for detailed explanation."]}),"\n",(0,o.jsx)(n.h2,{id:"p",children:"P"}),"\n",(0,o.jsx)(n.h3,{id:"path-planning",children:"Path Planning"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Definition"}),": The process of computing safe and efficient paths for robot movement from a start location to a goal location. For humanoid robots, path planning must consider humanoid-specific constraints including balance requirements, foot placement constraints, terrain adaptation needs, and obstacle avoidance."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Context"}),": Essential for enabling autonomous navigation in humanoid robots."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Related"}),": ",(0,o.jsx)(n.a,{href:"#nav2-navigation2",children:"Nav2"}),", ",(0,o.jsx)(n.a,{href:"#bipedal-movement-constraints",children:"Bipedal Movement Constraints"}),", ",(0,o.jsx)(n.a,{href:"#humanoid-navigation",children:"Humanoid Navigation"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Module Reference"}),": See ",(0,o.jsx)(n.a,{href:"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/nav2-path-planning",children:"Nav2 Path Planning section"})," for detailed explanation."]}),"\n",(0,o.jsx)(n.h3,{id:"photorealistic-simulation",children:"Photorealistic Simulation"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Definition"}),": Virtual environments created with realistic lighting, textures, materials, and visual appearance that closely match real-world conditions. Photorealistic simulation emphasizes visual fidelity to generate training data that is visually indistinguishable from real-world images."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Context"}),": Used in Isaac Sim to create synthetic training data for perception algorithms that matches real-world appearance."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Related"}),": ",(0,o.jsx)(n.a,{href:"#synthetic-training-data",children:"Synthetic Training Data"}),", ",(0,o.jsx)(n.a,{href:"#nvidia-isaac-sim",children:"NVIDIA Isaac Sim"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Module Reference"}),": See ",(0,o.jsx)(n.a,{href:"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/isaac-sim",children:"NVIDIA Isaac Sim section"})," for detailed explanation."]}),"\n",(0,o.jsx)(n.h2,{id:"r",children:"R"}),"\n",(0,o.jsx)(n.h3,{id:"real-time-navigation",children:"Real-Time Navigation"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Definition"}),": Robot navigation that processes sensor data and computes navigation decisions fast enough to enable smooth, responsive robot movement. Real-time navigation requires processing delays to be minimal (typically matching sensor frame rates) to avoid jerky motion or unsafe behavior."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Context"}),": Essential for autonomous humanoid robots that must navigate dynamically through changing environments."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Related"}),": ",(0,o.jsx)(n.a,{href:"#hardware-acceleration",children:"Hardware Acceleration"}),", ",(0,o.jsx)(n.a,{href:"#visual-slam-vslam",children:"Visual SLAM (VSLAM)"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Module Reference"}),": See ",(0,o.jsx)(n.a,{href:"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/isaac-ros",children:"Isaac ROS section"})," for detailed explanation."]}),"\n",(0,o.jsx)(n.h2,{id:"s",children:"S"}),"\n",(0,o.jsx)(n.h3,{id:"synthetic-training-data",children:"Synthetic Training Data"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Definition"}),": Data generated from simulation (rather than collected from physical systems) for training AI/ML algorithms. Synthetic training data includes images, depth maps, sensor readings, and ground truth annotations created programmatically in virtual environments. This data enables algorithm training without requiring physical data collection."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Context"}),": Used in Isaac Sim to generate training datasets for perception algorithms, eliminating the need for massive real-world data collection."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Related"}),": ",(0,o.jsx)(n.a,{href:"#photorealistic-simulation",children:"Photorealistic Simulation"}),", ",(0,o.jsx)(n.a,{href:"#nvidia-isaac-sim",children:"NVIDIA Isaac Sim"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Module Reference"}),": See ",(0,o.jsx)(n.a,{href:"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/isaac-sim",children:"NVIDIA Isaac Sim section"})," for detailed explanation."]}),"\n",(0,o.jsx)(n.h2,{id:"v",children:"V"}),"\n",(0,o.jsx)(n.h3,{id:"visual-slam-vslam",children:"Visual SLAM (VSLAM)"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Definition"}),": A system that uses visual sensors (cameras) to simultaneously map environments and localize the robot within those maps. VSLAM processes camera images to extract visual features, track robot movement, build environment maps, and determine robot position\u2014all in real-time."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Context"}),": Enables humanoid robots to understand their environment and navigate using visual information alone."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Related"}),": ",(0,o.jsx)(n.a,{href:"#hardware-acceleration",children:"Hardware Acceleration"}),", ",(0,o.jsx)(n.a,{href:"#isaac-ros",children:"Isaac ROS"}),", ",(0,o.jsx)(n.a,{href:"#real-time-navigation",children:"Real-Time Navigation"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Module Reference"}),": See ",(0,o.jsx)(n.a,{href:"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/isaac-ros",children:"Isaac ROS section"})," for detailed explanation."]}),"\n",(0,o.jsx)(n.h2,{id:"key-tool-definitions",children:"Key Tool Definitions"}),"\n",(0,o.jsx)(n.h3,{id:"isaac-ros",children:"Isaac ROS"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Definition"}),": A collection of hardware-accelerated ROS 2 packages that leverage GPU computing to process perception and navigation tasks in real-time. For humanoid robots, Isaac ROS primarily provides Visual SLAM (VSLAM) capabilities that enable real-time environmental understanding and robot localization."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Context"}),": Provides the perception component of the AI-robot brain, enabling real-time visual understanding."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Related"}),": ",(0,o.jsx)(n.a,{href:"#visual-slam-vslam",children:"Visual SLAM (VSLAM)"}),", ",(0,o.jsx)(n.a,{href:"#hardware-acceleration",children:"Hardware Acceleration"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Module Reference"}),": See ",(0,o.jsx)(n.a,{href:"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/isaac-ros",children:"Isaac ROS section"})," for detailed explanation."]}),"\n",(0,o.jsx)(n.h3,{id:"nvidia-isaac-sim",children:"NVIDIA Isaac Sim"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Definition"}),": A photorealistic simulation platform that creates highly realistic virtual environments with accurate lighting, textures, materials, and physics. Isaac Sim enables synthetic data generation for training perception algorithms, creating labeled training datasets programmatically without physical data collection."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Context"}),": Provides the training component of the AI-robot brain, generating synthetic data for perception algorithm development."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Related"}),": ",(0,o.jsx)(n.a,{href:"#photorealistic-simulation",children:"Photorealistic Simulation"}),", ",(0,o.jsx)(n.a,{href:"#synthetic-training-data",children:"Synthetic Training Data"})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Module Reference"}),": See ",(0,o.jsx)(n.a,{href:"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/isaac-sim",children:"NVIDIA Isaac Sim section"})," for detailed explanation."]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.em,{children:"This glossary will be expanded as additional modules are added to the textbook."})})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}}}]);