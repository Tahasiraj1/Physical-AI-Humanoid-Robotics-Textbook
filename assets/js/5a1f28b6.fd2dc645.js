"use strict";(globalThis.webpackChunk=globalThis.webpackChunk||[]).push([[1598],{7372:i=>{i.exports=JSON.parse('{"tag":{"label":"llm","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/llm","allTagsPath":"/Physical-AI-Humanoid-Robotics-Textbook/tags","count":4,"items":[{"id":"modules/module-4-vision-language-action/cognitive-planning","title":"Cognitive Planning with LLMs","description":"Understanding how LLMs perform cognitive planning by translating natural language commands into ROS 2 action sequences.","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/cognitive-planning"},{"id":"modules/module-4-vision-language-action/llm-robotics-convergence","title":"LLM-Robotics Convergence","description":"Understanding how Large Language Models (LLMs) converge with robotics to enable natural language interaction with humanoid robots.","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/llm-robotics-convergence"},{"id":"modules/module-4-vision-language-action/module-4-vision-language-action","title":"Module 4 - Vision-Language-Action (VLA)","description":"Introduction to Vision-Language-Action (VLA) systems, covering LLM-robotics convergence, voice-to-action, cognitive planning, and complete VLA pipeline integration.","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/"},{"id":"modules/module-4-vision-language-action/safety-validation","title":"Safety & Validation of LLM-Generated Plans","description":"Understanding how LLM-generated action plans are validated and executed safely, including plan verification and constraint checking.","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/safety-validation"}],"unlisted":false}}')}}]);