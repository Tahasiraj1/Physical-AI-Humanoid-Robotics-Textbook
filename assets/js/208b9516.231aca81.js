"use strict";(globalThis.webpackChunk=globalThis.webpackChunk||[]).push([[9648],{5333:(i,e,n)=>{n.r(e),n.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"modules/module-3-ai-robot-brain/isaac-sim","title":"NVIDIA Isaac Sim - Photorealistic Simulation","description":"Understanding NVIDIA Isaac Sim\'s capabilities for photorealistic simulation and synthetic data generation for training perception algorithms.","source":"@site/docs/modules/module-3-ai-robot-brain/isaac-sim.md","sourceDirName":"modules/module-3-ai-robot-brain","slug":"/modules/module-3-ai-robot-brain/isaac-sim","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/isaac-sim","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"nvidia-isaac-sim","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/nvidia-isaac-sim"},{"inline":true,"label":"photorealistic-simulation","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/photorealistic-simulation"},{"inline":true,"label":"synthetic-data","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/synthetic-data"},{"inline":true,"label":"training","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/training"},{"inline":true,"label":"perception-algorithms","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/perception-algorithms"}],"version":"current","sidebarPosition":3,"frontMatter":{"id":"isaac-sim","title":"NVIDIA Isaac Sim - Photorealistic Simulation","sidebar_position":3,"description":"Understanding NVIDIA Isaac Sim\'s capabilities for photorealistic simulation and synthetic data generation for training perception algorithms.","tags":["nvidia-isaac-sim","photorealistic-simulation","synthetic-data","training","perception-algorithms"],"learning_objectives":["lo-007"]},"sidebar":"textbookSidebar","previous":{"title":"AI-Robot Brain Concept","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/ai-robot-brain-concept"},"next":{"title":"Isaac ROS - Hardware-Accelerated VSLAM","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/isaac-ros"}}');var a=n(4848),s=n(8453);const r={id:"isaac-sim",title:"NVIDIA Isaac Sim - Photorealistic Simulation",sidebar_position:3,description:"Understanding NVIDIA Isaac Sim's capabilities for photorealistic simulation and synthetic data generation for training perception algorithms.",tags:["nvidia-isaac-sim","photorealistic-simulation","synthetic-data","training","perception-algorithms"],learning_objectives:["lo-007"]},o="NVIDIA Isaac Sim: Photorealistic Simulation",l={},c=[{value:"What is NVIDIA Isaac Sim?",id:"what-is-nvidia-isaac-sim",level:2},{value:"Key Capabilities",id:"key-capabilities",level:3},{value:"Photorealistic Simulation vs. General Simulation",id:"photorealistic-simulation-vs-general-simulation",level:2},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:2},{value:"Why Synthetic Data Matters",id:"why-synthetic-data-matters",level:3},{value:"How Isaac Sim Generates Training Data",id:"how-isaac-sim-generates-training-data",level:2},{value:"1. Environment Setup",id:"1-environment-setup",level:3},{value:"2. Camera Configuration",id:"2-camera-configuration",level:3},{value:"3. Data Generation Loop",id:"3-data-generation-loop",level:3},{value:"The Synthetic Data Generation Pipeline",id:"the-synthetic-data-generation-pipeline",level:2},{value:"Data Types Generated",id:"data-types-generated",level:3},{value:"Training Perception Algorithms",id:"training-perception-algorithms",level:2},{value:"Connection to Module 2 Simulation",id:"connection-to-module-2-simulation",level:2},{value:"Key Differences",id:"key-differences",level:3},{value:"Benefits for Humanoid Robotics",id:"benefits-for-humanoid-robotics",level:2},{value:"1. Safe Training Data Generation",id:"1-safe-training-data-generation",level:3},{value:"2. Perfect Ground Truth",id:"2-perfect-ground-truth",level:3},{value:"3. Unlimited Variation",id:"3-unlimited-variation",level:3},{value:"4. Domain Adaptation",id:"4-domain-adaptation",level:3},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(i){const e={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...i.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"nvidia-isaac-sim-photorealistic-simulation",children:"NVIDIA Isaac Sim: Photorealistic Simulation"})}),"\n",(0,a.jsxs)(e.p,{children:["NVIDIA Isaac Sim represents a leap beyond general physics simulation. While Module 2 introduced simulation fundamentals for testing robot behavior, Isaac Sim focuses on ",(0,a.jsx)(e.strong,{children:"photorealistic rendering"})," that generates realistic visual data for training AI perception algorithms. This capability bridges simulation and AI development, enabling robots to learn from synthetic data rather than requiring massive real-world data collection."]}),"\n",(0,a.jsx)(e.h2,{id:"what-is-nvidia-isaac-sim",children:"What is NVIDIA Isaac Sim?"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"NVIDIA Isaac Sim"})," is a photorealistic simulation platform that creates highly realistic virtual environments with accurate lighting, textures, materials, and physics. Unlike general physics simulators that focus on dynamics and collision detection, Isaac Sim emphasizes ",(0,a.jsx)(e.strong,{children:"visual fidelity"}),"\u2014creating images that are visually indistinguishable from real-world photographs."]}),"\n",(0,a.jsx)(e.h3,{id:"key-capabilities",children:"Key Capabilities"}),"\n",(0,a.jsx)(e.p,{children:"Isaac Sim enables:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Photorealistic rendering"}),": Environments with realistic lighting, shadows, reflections, and materials"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Synthetic data generation"}),": Automated creation of labeled training datasets (images, depth maps, annotations)"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Programmatic control"}),": Python APIs for scripting simulation scenarios and generating diverse training data"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Domain randomization"}),": Automatic variation of lighting, textures, object positions, and camera angles"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"These capabilities make Isaac Sim particularly valuable for training perception algorithms\u2014systems that process visual information to understand the environment."}),"\n",(0,a.jsx)(e.h2,{id:"photorealistic-simulation-vs-general-simulation",children:"Photorealistic Simulation vs. General Simulation"}),"\n",(0,a.jsx)(e.p,{children:"Understanding the difference between Isaac Sim's photorealistic simulation and general simulation (from Module 2) is important:"}),"\n",(0,a.jsxs)(e.table,{children:[(0,a.jsx)(e.thead,{children:(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.th,{children:"Aspect"}),(0,a.jsx)(e.th,{children:"General Simulation (Module 2)"}),(0,a.jsx)(e.th,{children:"Photorealistic Simulation (Isaac Sim)"})]})}),(0,a.jsxs)(e.tbody,{children:[(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Primary Focus"})}),(0,a.jsx)(e.td,{children:"Physics accuracy, dynamics, collisions"}),(0,a.jsx)(e.td,{children:"Visual realism, lighting, textures"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Use Case"})}),(0,a.jsx)(e.td,{children:"Testing robot behavior, validating dynamics"}),(0,a.jsx)(e.td,{children:"Training AI algorithms, generating datasets"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Output"})}),(0,a.jsx)(e.td,{children:"Robot state, joint angles, forces"}),(0,a.jsx)(e.td,{children:"Images, depth maps, semantic labels"})]}),(0,a.jsxs)(e.tr,{children:[(0,a.jsx)(e.td,{children:(0,a.jsx)(e.strong,{children:"Fidelity"})}),(0,a.jsx)(e.td,{children:"Sufficient for physics validation"}),(0,a.jsx)(e.td,{children:"Photorealistic for visual perception"})]})]})]}),"\n",(0,a.jsx)(e.p,{children:"While both types of simulation are valuable, photorealistic simulation serves a different purpose: creating visual training data that matches real-world appearance."}),"\n",(0,a.jsx)(e.h2,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,a.jsxs)(e.p,{children:["The core value of Isaac Sim lies in its ability to generate ",(0,a.jsx)(e.strong,{children:"synthetic training data"})," for perception algorithms. This process involves:"]}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Creating photorealistic environments"}),": Virtual worlds with realistic lighting, materials, and objects"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Rendering images"}),": Capturing camera views from different angles and positions"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Generating ground truth"}),": Automatically creating labels (object boundaries, depth maps, semantic segmentation)"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Automating variation"}),": Randomizing lighting, textures, and object configurations to create diverse datasets"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"why-synthetic-data-matters",children:"Why Synthetic Data Matters"}),"\n",(0,a.jsx)(e.p,{children:"Training perception algorithms traditionally requires:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Massive data collection"}),": Thousands or millions of real-world images"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Manual labeling"}),": Human annotators marking objects, boundaries, depths"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Controlled conditions"}),": Setting up specific scenarios to capture needed data"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Time and cost"}),": Significant resources for data collection and annotation"]}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:["Isaac Sim enables generating this data ",(0,a.jsx)(e.strong,{children:"programmatically in simulation"}),", eliminating the need for physical data collection while providing perfect ground truth labels automatically."]}),"\n",(0,a.jsx)(e.h2,{id:"how-isaac-sim-generates-training-data",children:"How Isaac Sim Generates Training Data"}),"\n",(0,a.jsx)(e.p,{children:"Isaac Sim generates training data through a systematic process:"}),"\n",(0,a.jsx)(e.h3,{id:"1-environment-setup",children:"1. Environment Setup"}),"\n",(0,a.jsx)(e.p,{children:"First, create a photorealistic virtual environment:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# Conceptual example: Isaac Sim synthetic data generation\n# Demonstrates how photorealistic simulation generates training data\n\nimport isaac_sim  # Conceptual import - tool not required for understanding\n\n# Create photorealistic scene with realistic lighting\nscene = isaac_sim.create_scene(\n    lighting="physically_based",  # Realistic light behavior\n    materials="photorealistic",    # Realistic surface properties\n    environment="indoor_office"    # Specific environment type\n)\n\n# Add objects with realistic textures and materials\nscene.add_object("table", position=[1.0, 0.5, 0.8], material="wood")\nscene.add_object("chair", position=[1.5, 0.0, 0.8], material="fabric")\n'})}),"\n",(0,a.jsx)(e.h3,{id:"2-camera-configuration",children:"2. Camera Configuration"}),"\n",(0,a.jsx)(e.p,{children:"Set up virtual cameras to capture images:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"# Configure camera with realistic parameters\ncamera = scene.add_camera(\n    position=[2.0, 1.5, 1.2],  # Camera location\n    resolution=(1920, 1080),    # Image resolution\n    fov=60                      # Field of view\n)\n"})}),"\n",(0,a.jsx)(e.h3,{id:"3-data-generation-loop",children:"3. Data Generation Loop"}),"\n",(0,a.jsx)(e.p,{children:"Generate multiple images with automatic variation:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# Generate synthetic training data\ntraining_data = []\n\nfor i in range(1000):  # Generate 1000 training images\n    # Randomize lighting conditions\n    scene.randomize_lighting()\n    \n    # Randomize object positions\n    scene.randomize_object_positions()\n    \n    # Render image with annotations\n    image_data = camera.render(\n        annotations=[\n            "rgb",              # Color image\n            "depth",            # Depth map\n            "semantic",         # Object labels\n            "bounding_boxes"    # Object boundaries\n        ]\n    )\n    \n    training_data.append(image_data)\n'})}),"\n",(0,a.jsx)(e.p,{children:"This process creates a diverse dataset automatically, with perfect ground truth labels included."}),"\n",(0,a.jsx)(e.h2,{id:"the-synthetic-data-generation-pipeline",children:"The Synthetic Data Generation Pipeline"}),"\n",(0,a.jsx)(e.p,{children:"The complete pipeline for generating training data follows these steps:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-mermaid",children:"graph LR\n    A[3D Environment<br/>Models & Materials] --\x3e B[Photorealistic<br/>Rendering]\n    B --\x3e C[RGB Image]\n    B --\x3e D[Depth Map]\n    B --\x3e E[Semantic Labels]\n    B --\x3e F[Bounding Boxes]\n    C --\x3e G[Training Dataset]\n    D --\x3e G\n    E --\x3e G\n    F --\x3e G\n    G --\x3e H[Perception<br/>Algorithm Training]\n    \n    style A fill:#e1f5ff\n    style B fill:#fff4e1\n    style G fill:#e8f5e9\n    style H fill:#fce4ec\n"})}),"\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.em,{children:"Figure: Synthetic data generation pipeline showing how Isaac Sim creates multiple data types simultaneously for training perception algorithms."})}),"\n",(0,a.jsx)(e.h3,{id:"data-types-generated",children:"Data Types Generated"}),"\n",(0,a.jsx)(e.p,{children:"Isaac Sim can generate multiple types of training data simultaneously:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"RGB Images"}),": Color images matching real-world appearance"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Depth Maps"}),": Distance information for every pixel"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Semantic Segmentation"}),": Object labels for each pixel"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Instance Segmentation"}),": Individual object identification"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Bounding Boxes"}),": Object boundaries and classifications"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Surface Normals"}),": Surface orientation information"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"All this data comes with perfect ground truth labels automatically\u2014no manual annotation required."}),"\n",(0,a.jsx)(e.h2,{id:"training-perception-algorithms",children:"Training Perception Algorithms"}),"\n",(0,a.jsx)(e.p,{children:"Once synthetic data is generated, it's used to train perception algorithms:"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Dataset Creation"}),": Thousands of synthetic images with variations"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Algorithm Training"}),": Neural networks learn to recognize objects, estimate depth, segment images"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Validation"}),": Algorithms tested on both synthetic and real-world data"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Deployment"}),": Trained algorithms deployed to real robots"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"This workflow demonstrates the value of synthetic data: algorithms learn from simulation, then apply that knowledge to real-world perception tasks."}),"\n",(0,a.jsx)(e.h2,{id:"connection-to-module-2-simulation",children:"Connection to Module 2 Simulation"}),"\n",(0,a.jsx)(e.p,{children:"Isaac Sim extends the simulation concepts from Module 2:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Module 2 (General Simulation)"}),": Focuses on physics accuracy for testing robot behavior and validating dynamics"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Isaac Sim (Photorealistic Simulation)"}),": Focuses on visual realism for training AI algorithms and generating datasets"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"Both types of simulation are valuable, but serve different purposes. General simulation validates that robots can move correctly; photorealistic simulation ensures perception algorithms can understand what they see."}),"\n",(0,a.jsx)(e.h3,{id:"key-differences",children:"Key Differences"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"General simulation"}),' answers: "Can the robot walk safely on this terrain?"']}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Photorealistic simulation"}),' answers: "Can the robot recognize and understand objects in this environment?"']}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"Both questions are important for autonomous robots, but require different simulation approaches."}),"\n",(0,a.jsx)(e.h2,{id:"benefits-for-humanoid-robotics",children:"Benefits for Humanoid Robotics"}),"\n",(0,a.jsx)(e.p,{children:"Isaac Sim's photorealistic simulation provides several advantages for humanoid robotics development:"}),"\n",(0,a.jsx)(e.h3,{id:"1-safe-training-data-generation",children:"1. Safe Training Data Generation"}),"\n",(0,a.jsx)(e.p,{children:"Unlike collecting real-world data which might require:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Operating expensive robots in various environments"}),"\n",(0,a.jsx)(e.li,{children:"Handling safety concerns"}),"\n",(0,a.jsx)(e.li,{children:"Dealing with unpredictable conditions"}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"Synthetic data generation is completely safe and controlled."}),"\n",(0,a.jsx)(e.h3,{id:"2-perfect-ground-truth",children:"2. Perfect Ground Truth"}),"\n",(0,a.jsx)(e.p,{children:"Manual annotation of real-world images is:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Time-consuming"}),"\n",(0,a.jsx)(e.li,{children:"Error-prone"}),"\n",(0,a.jsx)(e.li,{children:"Expensive"}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"Synthetic data provides perfect, automatic labels\u2014every pixel is correctly identified."}),"\n",(0,a.jsx)(e.h3,{id:"3-unlimited-variation",children:"3. Unlimited Variation"}),"\n",(0,a.jsx)(e.p,{children:"Real-world data collection is limited by:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Available environments"}),"\n",(0,a.jsx)(e.li,{children:"Time and resources"}),"\n",(0,a.jsx)(e.li,{children:"Safety constraints"}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"Simulation can generate unlimited variations of scenarios, lighting conditions, and object configurations."}),"\n",(0,a.jsx)(e.h3,{id:"4-domain-adaptation",children:"4. Domain Adaptation"}),"\n",(0,a.jsx)(e.p,{children:"Synthetic data can include scenarios that are:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Difficult to capture in real-world (extreme lighting, rare objects)"}),"\n",(0,a.jsx)(e.li,{children:"Dangerous to test (obstacle avoidance, emergency situations)"}),"\n",(0,a.jsx)(e.li,{children:"Expensive to recreate (multiple environments, weather conditions)"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,a.jsx)(e.p,{children:"NVIDIA Isaac Sim enables photorealistic simulation that generates synthetic training data for perception algorithms. Key points:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Photorealistic rendering"})," creates visually realistic virtual environments"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Synthetic data generation"})," automates creation of labeled training datasets"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Python APIs"})," enable programmatic control and automation"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Perfect ground truth"})," eliminates need for manual annotation"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Unlimited variation"})," enables diverse training scenarios"]}),"\n"]}),"\n",(0,a.jsx)(e.p,{children:"Isaac Sim bridges the gap between simulation and AI development, enabling robots to learn perception capabilities from synthetic data rather than requiring massive real-world data collection."}),"\n",(0,a.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,a.jsxs)(e.p,{children:["Now that you understand how Isaac Sim enables training through synthetic data generation, explore how that trained perception is deployed in real-time through ",(0,a.jsx)(e.strong,{children:"Isaac ROS"})," in the next section. Isaac ROS uses hardware acceleration to process visual information fast enough for real-time robot navigation."]})]})}function h(i={}){const{wrapper:e}={...(0,s.R)(),...i.components};return e?(0,a.jsx)(e,{...i,children:(0,a.jsx)(d,{...i})}):d(i)}},8453:(i,e,n)=>{n.d(e,{R:()=>r,x:()=>o});var t=n(6540);const a={},s=t.createContext(a);function r(i){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof i?i(e):{...e,...i}},[e,i])}function o(i){let e;return e=i.disableParentContext?"function"==typeof i.components?i.components(a):i.components||a:r(i.components),t.createElement(s.Provider,{value:e},i.children)}}}]);