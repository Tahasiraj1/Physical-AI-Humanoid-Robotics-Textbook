"use strict";(globalThis.webpackChunk=globalThis.webpackChunk||[]).push([[5959],{8453:(n,e,i)=>{i.d(e,{R:()=>s,x:()=>l});var t=i(6540);const o={},a=t.createContext(o);function s(n){const e=t.useContext(a);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),t.createElement(a.Provider,{value:e},n.children)}},9971:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>r,contentTitle:()=>l,default:()=>g,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"modules/module-4-vision-language-action/cognitive-planning","title":"Cognitive Planning with LLMs","description":"Understanding how LLMs perform cognitive planning by translating natural language commands into ROS 2 action sequences.","source":"@site/docs/modules/module-4-vision-language-action/cognitive-planning.md","sourceDirName":"modules/module-4-vision-language-action","slug":"/modules/module-4-vision-language-action/cognitive-planning","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/cognitive-planning","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"vla","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/vla"},{"inline":true,"label":"cognitive-planning","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/cognitive-planning"},{"inline":true,"label":"llm","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/llm"},{"inline":true,"label":"natural-language","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/natural-language"},{"inline":true,"label":"ros2","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/ros-2"},{"inline":true,"label":"action-generation","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/action-generation"},{"inline":true,"label":"humanoid-robotics","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/tags/humanoid-robotics"}],"version":"current","sidebarPosition":4,"frontMatter":{"id":"cognitive-planning","title":"Cognitive Planning with LLMs","sidebar_position":4,"description":"Understanding how LLMs perform cognitive planning by translating natural language commands into ROS 2 action sequences.","tags":["vla","cognitive-planning","llm","natural-language","ros2","action-generation","humanoid-robotics"],"learning_objectives":["lo-012"]},"sidebar":"textbookSidebar","previous":{"title":"Voice-to-Action Using OpenAI Whisper","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/voice-to-action"},"next":{"title":"Safety & Validation of LLM-Generated Plans","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/safety-validation"}}');var o=i(4848),a=i(8453);const s={id:"cognitive-planning",title:"Cognitive Planning with LLMs",sidebar_position:4,description:"Understanding how LLMs perform cognitive planning by translating natural language commands into ROS 2 action sequences.",tags:["vla","cognitive-planning","llm","natural-language","ros2","action-generation","humanoid-robotics"],learning_objectives:["lo-012"]},l="Cognitive Planning with LLMs",r={},c=[{value:"How LLMs Perform Cognitive Planning",id:"how-llms-perform-cognitive-planning",level:2},{value:"Provider-Agnostic Cognitive Planning",id:"provider-agnostic-cognitive-planning",level:3},{value:"Natural Language to ROS 2 Action Translation",id:"natural-language-to-ros-2-action-translation",level:2},{value:"Stage 1: Intent Understanding",id:"stage-1-intent-understanding",level:3},{value:"Stage 2: Goal Decomposition",id:"stage-2-goal-decomposition",level:3},{value:"Stage 3: Action Generation",id:"stage-3-action-generation",level:3},{value:"High-Level Command Decomposition",id:"high-level-command-decomposition",level:2},{value:"Example: &quot;Clean the room&quot;",id:"example-clean-the-room",level:3},{value:"The Decomposition Process",id:"the-decomposition-process",level:3},{value:"Natural Language Intent to Action Plan Relationship",id:"natural-language-intent-to-action-plan-relationship",level:2},{value:"Intent Layer",id:"intent-layer",level:3},{value:"Planning Layer",id:"planning-layer",level:3},{value:"Execution Layer",id:"execution-layer",level:3},{value:"Python Code Example: Provider-Agnostic LLM Prompt Structure",id:"python-code-example-provider-agnostic-llm-prompt-structure",level:2},{value:"Key Pattern Elements",id:"key-pattern-elements",level:3},{value:"Python Code Example: ROS 2 Action Generation",id:"python-code-example-ros-2-action-generation",level:2},{value:"Key Integration Points",id:"key-integration-points",level:3},{value:"Cross-Reference: Module 1 ROS 2 Actions",id:"cross-reference-module-1-ros-2-actions",level:2},{value:"Cognitive Planning Process Diagram",id:"cognitive-planning-process-diagram",level:2},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"cognitive-planning-with-llms",children:"Cognitive Planning with LLMs"})}),"\n",(0,o.jsx)(e.p,{children:"Cognitive planning is the intelligence layer of VLA systems, where Large Language Models translate natural language commands into executable robot action sequences. This section explores how LLMs perform this transformation and how high-level instructions become robot behaviors."}),"\n",(0,o.jsx)(e.h2,{id:"how-llms-perform-cognitive-planning",children:"How LLMs Perform Cognitive Planning"}),"\n",(0,o.jsx)(e.p,{children:"Large Language Models excel at understanding natural language and generating structured outputs. In cognitive planning, LLMs:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Interpret intent"}),": Understand what the user wants the robot to accomplish"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Decompose goals"}),": Break complex commands into manageable sub-tasks"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Generate actions"}),": Create sequences of robot actions that achieve the goal"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Structure output"}),": Format actions in a way that robots can execute"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"provider-agnostic-cognitive-planning",children:"Provider-Agnostic Cognitive Planning"}),"\n",(0,o.jsx)(e.p,{children:"Cognitive planning patterns are provider-agnostic, meaning the concepts apply regardless of which LLM provider or model is used. The key principles are:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Natural language understanding"}),": Interpreting user commands"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Goal decomposition"}),": Breaking complex tasks into steps"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Action sequence generation"}),": Creating executable robot behaviors"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Context awareness"}),": Understanding robot capabilities and constraints"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"natural-language-to-ros-2-action-translation",children:"Natural Language to ROS 2 Action Translation"}),"\n",(0,o.jsx)(e.p,{children:"The cognitive planning process translates natural language commands into ROS 2 action sequences through several stages:"}),"\n",(0,o.jsx)(e.h3,{id:"stage-1-intent-understanding",children:"Stage 1: Intent Understanding"}),"\n",(0,o.jsx)(e.p,{children:"The LLM analyzes the natural language command to understand:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Primary goal"}),": What the user wants accomplished"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Implicit requirements"}),": Unstated but necessary steps"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Constraints"}),": Limitations or preferences mentioned"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"stage-2-goal-decomposition",children:"Stage 2: Goal Decomposition"}),"\n",(0,o.jsx)(e.p,{children:"Complex commands are broken down into sub-goals:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Task identification"}),": Identifying all required tasks"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Dependency analysis"}),": Understanding which tasks depend on others"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Sequencing"}),": Determining the order of execution"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"stage-3-action-generation",children:"Stage 3: Action Generation"}),"\n",(0,o.jsx)(e.p,{children:"Each sub-goal is translated into ROS 2 actions:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Action selection"}),": Choosing appropriate ROS 2 actions"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Parameter specification"}),": Setting action parameters"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Sequence construction"}),": Ordering actions correctly"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"high-level-command-decomposition",children:"High-Level Command Decomposition"}),"\n",(0,o.jsx)(e.p,{children:'Let\'s examine how a high-level command like "Clean the room" is decomposed:'}),"\n",(0,o.jsx)(e.h3,{id:"example-clean-the-room",children:'Example: "Clean the room"'}),"\n",(0,o.jsx)(e.p,{children:"This command requires multiple steps:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Navigate to room"}),": Move to the target location"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Identify objects"}),": Find items that need to be cleaned or organized"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Pick up objects"}),": Grasp and manipulate items"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Place objects"}),": Put items in appropriate locations"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Verify completion"}),": Check that the task is complete"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"Each step becomes one or more ROS 2 actions:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Navigation actions for movement"}),"\n",(0,o.jsx)(e.li,{children:"Perception actions for object identification"}),"\n",(0,o.jsx)(e.li,{children:"Manipulation actions for picking and placing"}),"\n",(0,o.jsx)(e.li,{children:"Verification actions for task completion"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"the-decomposition-process",children:"The Decomposition Process"}),"\n",(0,o.jsx)(e.p,{children:"The LLM performs decomposition by:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Understanding context"}),': What "clean" means in this context']}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Identifying sub-tasks"}),": Breaking the goal into actionable steps"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Considering dependencies"}),": Some steps must happen before others"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Handling ambiguity"}),": Making reasonable assumptions when commands are vague"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"natural-language-intent-to-action-plan-relationship",children:"Natural Language Intent to Action Plan Relationship"}),"\n",(0,o.jsx)(e.p,{children:"The relationship between natural language intent and action plans follows this structure:"}),"\n",(0,o.jsx)(e.h3,{id:"intent-layer",children:"Intent Layer"}),"\n",(0,o.jsx)(e.p,{children:"The user's natural language command expresses:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Goal"}),": What should be accomplished"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Context"}),": The situation or environment"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Constraints"}),": Limitations or preferences"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"planning-layer",children:"Planning Layer"}),"\n",(0,o.jsx)(e.p,{children:"The LLM generates a cognitive plan containing:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"High-level plan"}),": The overall strategy"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Sub-goals"}),": Individual tasks to accomplish"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Action sequence"}),": Ordered list of robot actions"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Execution parameters"}),": Settings for each action"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"execution-layer",children:"Execution Layer"}),"\n",(0,o.jsx)(e.p,{children:"ROS 2 actions execute the plan:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Action messages"}),": Standard ROS 2 action format"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Parameter values"}),": Specific values for each action"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Feedback handling"}),": Monitoring action progress"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Error recovery"}),": Handling failures gracefully"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"python-code-example-provider-agnostic-llm-prompt-structure",children:"Python Code Example: Provider-Agnostic LLM Prompt Structure"}),"\n",(0,o.jsx)(e.p,{children:"The following example demonstrates a provider-agnostic pattern for cognitive planning. This shows the structure of prompts and responses, not specific LLM provider APIs:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'# Provider-Agnostic Cognitive Planning Pattern\n# This example shows the structure of LLM prompts for cognitive planning\n\nclass CognitivePlanner:\n    """\n    Cognitive planning system that uses LLMs to translate natural language\n    to ROS 2 action sequences. This demonstrates provider-agnostic patterns.\n    """\n    \n    def __init__(self, llm_client):\n        """\n        Initialize with an LLM client (provider-agnostic interface).\n        The actual client could be from any LLM provider.\n        """\n        self.llm_client = llm_client\n    \n    def create_planning_prompt(self, natural_language_command, robot_context):\n        """\n        Create a prompt for cognitive planning.\n        This pattern works with any LLM provider.\n        """\n        prompt = f"""\n        You are a cognitive planning system for a humanoid robot.\n        \n        User Command: "{natural_language_command}"\n        \n        Robot Context:\n        - Current location: {robot_context[\'location\']}\n        - Available capabilities: {robot_context[\'capabilities\']}\n        - Environment: {robot_context[\'environment\']}\n        \n        Task: Translate this command into a sequence of ROS 2 actions.\n        \n        Output format:\n        1. Decompose the command into sub-goals\n        2. For each sub-goal, specify:\n           - Action type (navigation, manipulation, perception)\n           - Action parameters\n           - Dependencies on other actions\n        \n        Generate the action sequence:\n        """\n        return prompt\n    \n    def plan_actions(self, command, context):\n        """\n        Generate ROS 2 action sequence from natural language command.\n        This demonstrates the cognitive planning process.\n        """\n        # Create planning prompt\n        prompt = self.create_planning_prompt(command, context)\n        \n        # Call LLM (provider-agnostic - works with any LLM)\n        response = self.llm_client.generate(prompt)\n        \n        # Parse response into action sequence\n        action_sequence = self.parse_llm_response(response)\n        \n        return action_sequence\n    \n    def parse_llm_response(self, llm_response):\n        """\n        Parse LLM response into structured action sequence.\n        This converts natural language output to ROS 2 actions.\n        """\n        # Parse the LLM\'s structured response\n        # Extract action types, parameters, and sequence\n        # This is a simplified example\n        actions = []\n        \n        # In practice, you would parse the LLM\'s structured output\n        # and convert it to ROS 2 action format\n        \n        return actions\n'})}),"\n",(0,o.jsx)(e.h3,{id:"key-pattern-elements",children:"Key Pattern Elements"}),"\n",(0,o.jsx)(e.p,{children:"This example demonstrates:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Provider-agnostic interface"}),": Works with any LLM provider"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Prompt structure"}),": How to structure prompts for cognitive planning"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Context integration"}),": Including robot state and capabilities"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Response parsing"}),": Converting LLM output to action sequences"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"python-code-example-ros-2-action-generation",children:"Python Code Example: ROS 2 Action Generation"}),"\n",(0,o.jsx)(e.p,{children:"The following example shows how cognitive plans are converted to ROS 2 actions:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# ROS 2 Action Generation from Cognitive Plans\n# This example shows how cognitive plans become executable ROS 2 actions\n\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.action import ActionClient\nfrom geometry_msgs.msg import PoseStamped\nfrom manipulation_msgs.action import PickPlace  # Example action type\n\nclass ActionExecutor(Node):\n    \"\"\"\n    ROS 2 node that executes action sequences generated by cognitive planning.\n    This demonstrates how cognitive plans become ROS 2 actions.\n    \"\"\"\n    \n    def __init__(self):\n        super().__init__('action_executor')\n        \n        # Action clients for different robot capabilities\n        self.navigation_client = ActionClient(self, NavigateToPose, 'navigate_to_pose')\n        self.manipulation_client = ActionClient(self, PickPlace, 'pick_place')\n        self.perception_client = ActionClient(self, DetectObjects, 'detect_objects')\n    \n    def execute_cognitive_plan(self, cognitive_plan):\n        \"\"\"\n        Execute a cognitive plan by converting it to ROS 2 actions.\n        This demonstrates the translation from cognitive plan to execution.\n        \"\"\"\n        action_sequence = []\n        \n        # Convert each step in the cognitive plan to ROS 2 actions\n        for step in cognitive_plan.steps:\n            if step.action_type == 'navigate':\n                action = self.create_navigation_action(step)\n            elif step.action_type == 'manipulate':\n                action = self.create_manipulation_action(step)\n            elif step.action_type == 'perceive':\n                action = self.create_perception_action(step)\n            \n            action_sequence.append(action)\n        \n        # Execute actions in sequence\n        for action in action_sequence:\n            self.execute_action(action)\n    \n    def create_navigation_action(self, step):\n        \"\"\"\n        Create a ROS 2 navigation action from cognitive plan step.\n        \"\"\"\n        goal_msg = NavigateToPose.Goal()\n        goal_msg.pose = step.target_pose\n        goal_msg.behavior_tree = step.behavior_tree\n        \n        return {\n            'client': self.navigation_client,\n            'goal': goal_msg,\n            'action_type': 'navigate'\n        }\n    \n    def create_manipulation_action(self, step):\n        \"\"\"\n        Create a ROS 2 manipulation action from cognitive plan step.\n        \"\"\"\n        goal_msg = PickPlace.Goal()\n        goal_msg.object_id = step.object_id\n        goal_msg.pick_pose = step.pick_pose\n        goal_msg.place_pose = step.place_pose\n        \n        return {\n            'client': self.manipulation_client,\n            'goal': goal_msg,\n            'action_type': 'manipulate'\n        }\n    \n    def execute_action(self, action):\n        \"\"\"\n        Execute a single ROS 2 action.\n        This demonstrates action execution from cognitive plans.\n        \"\"\"\n        client = action['client']\n        goal = action['goal']\n        \n        # Send goal and wait for result\n        client.wait_for_server()\n        send_goal_future = client.send_goal_async(goal)\n        # Handle feedback and completion...\n"})}),"\n",(0,o.jsx)(e.h3,{id:"key-integration-points",children:"Key Integration Points"}),"\n",(0,o.jsx)(e.p,{children:"This example demonstrates:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Action client setup"}),": ROS 2 action clients for different capabilities"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Plan conversion"}),": Converting cognitive plan steps to ROS 2 actions"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Action execution"}),": Executing actions in the correct sequence"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Feedback handling"}),": Monitoring action progress (simplified in example)"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"cross-reference-module-1-ros-2-actions",children:"Cross-Reference: Module 1 ROS 2 Actions"}),"\n",(0,o.jsxs)(e.p,{children:["Cognitive planning generates ROS 2 actions that follow the patterns established in ",(0,o.jsx)(e.a,{href:"/modules/module-1-ros2-nervous-system/ros2-fundamentals",children:"Module 1: The Robotic Nervous System (ROS 2)"}),". The actions generated by cognitive planning use:"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS 2 action format"}),": Standard action message types"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Action clients"}),": ROS 2 action client patterns"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Feedback mechanisms"}),": Action feedback for monitoring progress"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Result handling"}),": Processing action completion and results"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"Understanding ROS 2 actions from Module 1 is essential for comprehending how cognitive plans become executable robot behaviors."}),"\n",(0,o.jsx)(e.h2,{id:"cognitive-planning-process-diagram",children:"Cognitive Planning Process Diagram"}),"\n",(0,o.jsx)(e.p,{children:"The following diagram illustrates the complete cognitive planning process:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-mermaid",children:"flowchart TD\n    A[Natural Language Command] --\x3e B[LLM Intent Understanding]\n    B --\x3e C[Goal Decomposition]\n    C --\x3e D[Sub-Goal Identification]\n    D --\x3e E[Action Sequence Generation]\n    E --\x3e F[ROS 2 Action Creation]\n    F --\x3e G[Action Parameter Specification]\n    G --\x3e H[Action Execution]\n    H --\x3e I[Robot Behavior]\n    \n    style A fill:#e1f5ff\n    style B fill:#fff4e1\n    style E fill:#e8f5e9\n    style I fill:#fce4ec\n"})}),"\n",(0,o.jsx)(e.p,{children:"This diagram shows how natural language flows through cognitive planning to become robot actions."}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:'Cognitive planning enables LLMs to translate natural language commands into ROS 2 action sequences. The process involves intent understanding, goal decomposition, and action generation. High-level commands like "Clean the room" are decomposed into executable robot behaviors through provider-agnostic LLM patterns. Understanding cognitive planning is essential for comprehending how VLA systems enable natural language robot control.'}),"\n",(0,o.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsxs)(e.p,{children:["Now that you understand cognitive planning, proceed to ",(0,o.jsx)(e.a,{href:"/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/safety-validation",children:"Safety & Validation"})," to learn how LLM-generated action plans are validated and executed safely."]})]})}function g(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}}}]);