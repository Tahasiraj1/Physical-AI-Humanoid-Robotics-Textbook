"use strict";(globalThis.webpackChunk=globalThis.webpackChunk||[]).push([[3005],{3511:o=>{o.exports=JSON.parse('{"tag":{"label":"robotics","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/tags/robotics","allTagsPath":"/Physical-AI-Humanoid-Robotics-Textbook/ur/tags","count":2,"items":[{"id":"modules/module-4-vision-language-action/llm-robotics-convergence","title":"LLM-Robotics Convergence","description":"\u0633\u0645\u062c\u06be\u0646\u0627 \u06a9\u06c1 Large Language Models (LLMs) \u06a9\u06cc\u0633\u06d2 robotics \u06a9\u06d2 \u0633\u0627\u062a\u06be converge \u06c1\u0648\u062a\u06d2 \u06c1\u06cc\u06ba natural language interaction enable \u06a9\u0631\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 humanoid robots \u06a9\u06d2 \u0633\u0627\u062a\u06be\u06d4","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/modules/module-4-vision-language-action/llm-robotics-convergence"},{"id":"modules/module-4-vision-language-action/module-4-vision-language-action","title":"\u0645\u0627\u0688\u06cc\u0648\u0644 4 - Vision-Language-Action (VLA)","description":"Vision-Language-Action (VLA) systems \u06a9\u0627 \u062a\u0639\u0627\u0631\u0641\u060c LLM-robotics convergence\u060c voice-to-action\u060c cognitive planning\u060c \u0627\u0648\u0631 complete VLA pipeline integration \u06a9\u0627 \u0627\u062d\u0627\u0637\u06c1 \u06a9\u0631\u062a\u06d2 \u06c1\u0648\u0626\u06d2\u06d4","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/modules/module-4-vision-language-action/"}],"unlisted":false}}')}}]);