"use strict";(globalThis.webpackChunk=globalThis.webpackChunk||[]).push([[569],{3101:i=>{i.exports=JSON.parse('{"tag":{"label":"llm","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/tags/llm","allTagsPath":"/Physical-AI-Humanoid-Robotics-Textbook/ur/tags","count":4,"items":[{"id":"modules/module-4-vision-language-action/safety-validation","title":"LLM-Generated Plans \u06a9\u06cc Safety & Validation","description":"\u0633\u0645\u062c\u06be\u0646\u0627 \u06a9\u06c1 LLM-generated action plans \u06a9\u06cc\u0633\u06d2 validated \u0627\u0648\u0631 safely executed \u06c1\u0648\u062a\u06d2 \u06c1\u06cc\u06ba\u060c plan verification \u0627\u0648\u0631 constraint checking \u0634\u0627\u0645\u0644 \u06a9\u0631\u062a\u06d2 \u06c1\u0648\u0626\u06d2\u06d4","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/modules/module-4-vision-language-action/safety-validation"},{"id":"modules/module-4-vision-language-action/llm-robotics-convergence","title":"LLM-Robotics Convergence","description":"\u0633\u0645\u062c\u06be\u0646\u0627 \u06a9\u06c1 Large Language Models (LLMs) \u06a9\u06cc\u0633\u06d2 robotics \u06a9\u06d2 \u0633\u0627\u062a\u06be converge \u06c1\u0648\u062a\u06d2 \u06c1\u06cc\u06ba natural language interaction enable \u06a9\u0631\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 humanoid robots \u06a9\u06d2 \u0633\u0627\u062a\u06be\u06d4","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/modules/module-4-vision-language-action/llm-robotics-convergence"},{"id":"modules/module-4-vision-language-action/cognitive-planning","title":"LLMs \u06a9\u06d2 \u0633\u0627\u062a\u06be Cognitive Planning","description":"\u0633\u0645\u062c\u06be\u0646\u0627 \u06a9\u06c1 LLMs \u06a9\u06cc\u0633\u06d2 cognitive planning perform \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba natural language commands translate \u06a9\u0631 \u06a9\u06d2 ROS 2 action sequences \u0645\u06cc\u06ba\u06d4","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/modules/module-4-vision-language-action/cognitive-planning"},{"id":"modules/module-4-vision-language-action/module-4-vision-language-action","title":"\u0645\u0627\u0688\u06cc\u0648\u0644 4 - Vision-Language-Action (VLA)","description":"Vision-Language-Action (VLA) systems \u06a9\u0627 \u062a\u0639\u0627\u0631\u0641\u060c LLM-robotics convergence\u060c voice-to-action\u060c cognitive planning\u060c \u0627\u0648\u0631 complete VLA pipeline integration \u06a9\u0627 \u0627\u062d\u0627\u0637\u06c1 \u06a9\u0631\u062a\u06d2 \u06c1\u0648\u0626\u06d2\u06d4","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/modules/module-4-vision-language-action/"}],"unlisted":false}}')}}]);