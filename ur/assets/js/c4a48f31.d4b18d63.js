"use strict";(globalThis.webpackChunk=globalThis.webpackChunk||[]).push([[5407],{3679:i=>{i.exports=JSON.parse('{"tag":{"label":"vision-language-action","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/tags/vision-language-action","allTagsPath":"/Physical-AI-Humanoid-Robotics-Textbook/ur/tags","count":1,"items":[{"id":"modules/module-4-vision-language-action/module-4-vision-language-action","title":"\u0645\u0627\u0688\u06cc\u0648\u0644 4 - Vision-Language-Action (VLA)","description":"Vision-Language-Action (VLA) systems \u06a9\u0627 \u062a\u0639\u0627\u0631\u0641\u060c LLM-robotics convergence\u060c voice-to-action\u060c cognitive planning\u060c \u0627\u0648\u0631 complete VLA pipeline integration \u06a9\u0627 \u0627\u062d\u0627\u0637\u06c1 \u06a9\u0631\u062a\u06d2 \u06c1\u0648\u0626\u06d2\u06d4","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/modules/module-4-vision-language-action/"}],"unlisted":false}}')}}]);