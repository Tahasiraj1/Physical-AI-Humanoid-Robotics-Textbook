"use strict";(globalThis.webpackChunk=globalThis.webpackChunk||[]).push([[2424],{8453:(n,e,i)=>{i.d(e,{R:()=>a,x:()=>l});var o=i(6540);const s={},t=o.createContext(s);function a(n){const e=o.useContext(t);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:a(n.components),o.createElement(t.Provider,{value:e},n.children)}},8783:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>r,contentTitle:()=>l,default:()=>d,frontMatter:()=>a,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"modules/module-4-vision-language-action/module-4-vision-language-action","title":"\u0645\u0627\u0688\u06cc\u0648\u0644 4 - Vision-Language-Action (VLA)","description":"Vision-Language-Action (VLA) systems \u06a9\u0627 \u062a\u0639\u0627\u0631\u0641\u060c LLM-robotics convergence\u060c voice-to-action\u060c cognitive planning\u060c \u0627\u0648\u0631 complete VLA pipeline integration \u06a9\u0627 \u0627\u062d\u0627\u0637\u06c1 \u06a9\u0631\u062a\u06d2 \u06c1\u0648\u0626\u06d2\u06d4","source":"@site/i18n/ur/docusaurus-plugin-content-docs/current/modules/module-4-vision-language-action/index.md","sourceDirName":"modules/module-4-vision-language-action","slug":"/modules/module-4-vision-language-action/","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/modules/module-4-vision-language-action/","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"vla","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/tags/vla"},{"inline":true,"label":"vision-language-action","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/tags/vision-language-action"},{"inline":true,"label":"llm","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/tags/llm"},{"inline":true,"label":"robotics","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/tags/robotics"},{"inline":true,"label":"voice-to-action","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/tags/voice-to-action"},{"inline":true,"label":"cognitive-planning","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/tags/cognitive-planning"},{"inline":true,"label":"humanoid-robotics","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/tags/humanoid-robotics"}],"version":"current","sidebarPosition":4,"frontMatter":{"id":"module-4-vision-language-action","title":"\u0645\u0627\u0688\u06cc\u0648\u0644 4 - Vision-Language-Action (VLA)","sidebar_position":4,"description":"Vision-Language-Action (VLA) systems \u06a9\u0627 \u062a\u0639\u0627\u0631\u0641\u060c LLM-robotics convergence\u060c voice-to-action\u060c cognitive planning\u060c \u0627\u0648\u0631 complete VLA pipeline integration \u06a9\u0627 \u0627\u062d\u0627\u0637\u06c1 \u06a9\u0631\u062a\u06d2 \u06c1\u0648\u0626\u06d2\u06d4","tags":["vla","vision-language-action","llm","robotics","voice-to-action","cognitive-planning","humanoid-robotics"],"learning_objectives":["lo-010","lo-011","lo-012","lo-013"]},"sidebar":"textbookSidebar","previous":{"title":"Glossary","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/modules/module-3-ai-robot-brain/glossary"},"next":{"title":"\u062a\u0639\u0627\u0631\u0641 - Vision-Language-Action (VLA) Systems","permalink":"/Physical-AI-Humanoid-Robotics-Textbook/ur/modules/module-4-vision-language-action/introduction"}}');var s=i(4848),t=i(8453);const a={id:"module-4-vision-language-action",title:"\u0645\u0627\u0688\u06cc\u0648\u0644 4 - Vision-Language-Action (VLA)",sidebar_position:4,description:"Vision-Language-Action (VLA) systems \u06a9\u0627 \u062a\u0639\u0627\u0631\u0641\u060c LLM-robotics convergence\u060c voice-to-action\u060c cognitive planning\u060c \u0627\u0648\u0631 complete VLA pipeline integration \u06a9\u0627 \u0627\u062d\u0627\u0637\u06c1 \u06a9\u0631\u062a\u06d2 \u06c1\u0648\u0626\u06d2\u06d4",tags:["vla","vision-language-action","llm","robotics","voice-to-action","cognitive-planning","humanoid-robotics"],learning_objectives:["lo-010","lo-011","lo-012","lo-013"]},l="\u0645\u0627\u0688\u06cc\u0648\u0644 4: Vision-Language-Action (VLA)",r={},c=[{value:"Overview",id:"overview",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"\u067e\u06cc\u0634\u06af\u06cc \u0636\u0631\u0648\u0631\u06cc\u0627\u062a",id:"\u067e\u06cc\u0634\u06af\u06cc-\u0636\u0631\u0648\u0631\u06cc\u0627\u062a",level:2},{value:"\u0645\u0627\u0688\u06cc\u0648\u0644 \u06a9\u06cc \u0633\u0627\u062e\u062a",id:"\u0645\u0627\u0688\u06cc\u0648\u0644-\u06a9\u06cc-\u0633\u0627\u062e\u062a",level:2},{value:"Estimated Reading Time",id:"estimated-reading-time",level:2},{value:"Next Steps",id:"next-steps",level:2}];function u(n){const e={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"\u0645\u0627\u0688\u06cc\u0648\u0644-4-vision-language-action-vla",children:"\u0645\u0627\u0688\u06cc\u0648\u0644 4: Vision-Language-Action (VLA)"})}),"\n",(0,s.jsx)(e.p,{children:"\u062c\u0633\u0645\u0627\u0646\u06cc \u0645\u0635\u0646\u0648\u0639\u06cc \u0630\u06c1\u0627\u0646\u062a \u0627\u0648\u0631 \u0627\u0646\u0633\u0627\u0646\u06cc \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u06a9\u06cc \u062f\u0631\u0633\u06cc \u06a9\u062a\u0627\u0628 \u06a9\u06d2 \u0645\u0627\u0688\u06cc\u0648\u0644 4 \u0645\u06cc\u06ba \u062e\u0648\u0634 \u0622\u0645\u062f\u06cc\u062f\u06d4 \u06cc\u06c1 \u0645\u0627\u0688\u06cc\u0648\u0644 Large Language Models (LLMs) \u0627\u0648\u0631 robotics \u06a9\u06d2 convergence explore \u06a9\u0631\u062a\u0627 \u06c1\u06d2\u060c natural language interaction \u06a9\u0648 \u0645\u0645\u06a9\u0646 \u0628\u0646\u0627\u062a\u06d2 \u06c1\u0648\u0626\u06d2 humanoid robots \u06a9\u06d2 \u0633\u0627\u062a\u06be Vision-Language-Action (VLA) systems \u06a9\u06d2 \u0630\u0631\u06cc\u0639\u06d2\u06d4"}),"\n",(0,s.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(e.p,{children:"Vision-Language-Action (VLA) transformative approach represent \u06a9\u0631\u062a\u0627 \u06c1\u06d2 humanoid robot control \u06a9\u06d2 \u0644\u06cc\u06d2\u060c \u062c\u06c1\u0627\u06ba natural language commands robot actions \u0645\u06cc\u06ba translate \u06c1\u0648\u062a\u06d2 \u06c1\u06cc\u06ba vision\u060c language processing\u060c \u0627\u0648\u0631 action execution \u06a9\u06d2 integration \u06a9\u06d2 \u0630\u0631\u06cc\u0639\u06d2\u06d4 \u06cc\u06c1 \u0645\u0627\u0688\u06cc\u0648\u0644 \u0622\u067e \u06a9\u0648 \u0633\u0645\u062c\u06be\u0646\u06d2 \u0645\u06cc\u06ba \u0645\u062f\u062f \u06a9\u0631\u06d2 \u06af\u0627:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"\u06a9\u06cc\u0633\u06d2 LLMs robotics \u06a9\u06d2 \u0633\u0627\u062a\u06be converge \u06c1\u0648\u062a\u06d2 \u06c1\u06cc\u06ba conversational robot control enable \u06a9\u0631\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2"}),"\n",(0,s.jsx)(e.li,{children:"Voice-to-action capabilities speech recognition technology \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631\u062a\u06d2 \u06c1\u0648\u0626\u06d2"}),"\n",(0,s.jsx)(e.li,{children:"Cognitive planning \u062c\u0648 natural language \u06a9\u0648 robot behaviors \u0645\u06cc\u06ba translate \u06a9\u0631\u062a\u06cc \u06c1\u06d2"}),"\n",(0,s.jsx)(e.li,{children:"Complete VLA pipeline integration voice input \u0633\u06d2 physical action \u062a\u06a9"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,s.jsx)(e.p,{children:"\u0627\u0633 \u0645\u0627\u0688\u06cc\u0648\u0644 \u06a9\u06d2 \u0622\u062e\u0631 \u062a\u06a9\u060c \u0622\u067e \u0642\u0627\u0628\u0644 \u06c1\u0648\u06ba \u06af\u06d2:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Vision-Language-Action (VLA) explain \u06a9\u0631\u06cc\u06ba"})," \u0627\u0648\u0631 \u0627\u0633 \u06a9\u06cc significance modern humanoid robotics \u0645\u06cc\u06ba"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Voice-to-action systems \u0633\u0645\u062c\u06be\u06cc\u06ba"})," \u0627\u0648\u0631 \u06a9\u06cc\u0633\u06d2 OpenAI Whisper natural language input enable \u06a9\u0631\u062a\u0627 \u06c1\u06d2"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Cognitive planning describe \u06a9\u0631\u06cc\u06ba"})," \u0627\u0648\u0631 \u06a9\u06cc\u0633\u06d2 LLMs natural language commands \u06a9\u0648 ROS 2 action sequences \u0645\u06cc\u06ba translate \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Complete VLA pipeline explain \u06a9\u0631\u06cc\u06ba"})," voice input \u0633\u06d2 physical action \u062a\u06a9 capstone project \u06a9\u06d2 \u0630\u0631\u06cc\u0639\u06d2"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"VLA concepts connect \u06a9\u0631\u06cc\u06ba"})," previous modules (ROS 2\u060c simulation\u060c perception) \u0633\u06d2 \u0627\u0648\u0631 system integration \u0633\u0645\u062c\u06be\u06cc\u06ba"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"\u067e\u06cc\u0634\u06af\u06cc-\u0636\u0631\u0648\u0631\u06cc\u0627\u062a",children:"\u067e\u06cc\u0634\u06af\u06cc \u0636\u0631\u0648\u0631\u06cc\u0627\u062a"}),"\n",(0,s.jsx)(e.p,{children:"\u0627\u0633 \u0645\u0627\u0688\u06cc\u0648\u0644 \u06a9\u0648 \u0634\u0631\u0648\u0639 \u06a9\u0631\u0646\u06d2 \u0633\u06d2 \u067e\u06c1\u0644\u06d2\u060c \u0622\u067e \u0646\u06d2 \u0645\u06a9\u0645\u0644 \u06a9\u0631 \u0644\u06cc\u0627 \u06c1\u0648\u0646\u0627 \u0686\u0627\u06c1\u06cc\u06d2:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"\u0645\u0627\u0688\u06cc\u0648\u0644 1: The Robotic Nervous System (ROS 2)"})," - ROS 2 actions \u0627\u0648\u0631 communication patterns \u06a9\u06cc \u0633\u0645\u062c\u06be"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"\u0645\u0627\u0688\u06cc\u0648\u0644 2: Digital Twins - Simulation & Sensors"})," - Simulation fundamentals \u0627\u0648\u0631 sensor integration \u06a9\u06cc \u0633\u0645\u062c\u06be"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"\u0645\u0627\u0688\u06cc\u0648\u0644 3: The AI-Robot Brain (NVIDIA Isaac\u2122)"})," - Perception\u060c navigation\u060c \u0627\u0648\u0631 computer vision \u06a9\u06cc \u0633\u0645\u062c\u06be"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"\u0622\u067e \u06a9\u06d2 \u067e\u0627\u0633 \u0628\u06be\u06cc \u06c1\u0648\u0646\u0627 \u0686\u0627\u06c1\u06cc\u06d2:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Python programming knowledge"})," - Python syntax \u0627\u0648\u0631 basic programming concepts \u0633\u06d2 \u0648\u0627\u0642\u0641\u06cc\u062a"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"\u0628\u0646\u06cc\u0627\u062f\u06cc AI/ML concepts"})," - LLMs\u060c neural networks\u060c \u0627\u0648\u0631 natural language processing \u06a9\u06cc conceptual understanding"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"\u0645\u0627\u0688\u06cc\u0648\u0644-\u06a9\u06cc-\u0633\u0627\u062e\u062a",children:"\u0645\u0627\u0688\u06cc\u0648\u0644 \u06a9\u06cc \u0633\u0627\u062e\u062a"}),"\n",(0,s.jsx)(e.p,{children:"\u06cc\u06c1 \u0645\u0627\u0688\u06cc\u0648\u0644 \u062f\u0631\u062c \u0630\u06cc\u0644 sections \u0645\u06cc\u06ba \u0645\u0646\u0638\u0645 \u06c1\u06d2:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:(0,s.jsx)(e.a,{href:"/ur/modules/module-4-vision-language-action/introduction",children:"\u062a\u0639\u0627\u0631\u0641"})})," - Learning objectives\u060c prerequisites\u060c \u0627\u0648\u0631 module overview"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:(0,s.jsx)(e.a,{href:"/ur/modules/module-4-vision-language-action/llm-robotics-convergence",children:"LLM-Robotics Convergence"})})," - \u0633\u0645\u062c\u06be\u0646\u0627 \u06a9\u06c1 LLMs \u0627\u0648\u0631 robotics \u06a9\u06cc\u0633\u06d2 converge \u06c1\u0648\u062a\u06d2 \u06c1\u06cc\u06ba"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:(0,s.jsx)(e.a,{href:"/ur/modules/module-4-vision-language-action/voice-to-action",children:"Voice-to-Action"})})," - OpenAI Whisper \u0627\u0648\u0631 voice-to-action pipeline"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:(0,s.jsx)(e.a,{href:"/ur/modules/module-4-vision-language-action/cognitive-planning",children:"Cognitive Planning"})})," - LLM cognitive planning \u0627\u0648\u0631 ROS 2 action generation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:(0,s.jsx)(e.a,{href:"/ur/modules/module-4-vision-language-action/safety-validation",children:"Safety & Validation"})})," - LLM-generated plans \u06a9\u06cc safety \u0627\u0648\u0631 validation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:(0,s.jsx)(e.a,{href:"/ur/modules/module-4-vision-language-action/capstone-project",children:"Capstone Project"})})," - Complete VLA pipeline demonstration"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:(0,s.jsx)(e.a,{href:"/ur/modules/module-4-vision-language-action/module-integration",children:"Module Integration"})})," - VLA \u06a9\u0648 previous modules \u0633\u06d2 connect \u06a9\u0631\u0646\u0627"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:(0,s.jsx)(e.a,{href:"/ur/modules/module-4-vision-language-action/glossary",children:"Glossary"})})," - \u06a9\u0644\u06cc\u062f\u06cc \u0627\u0635\u0637\u0644\u0627\u062d\u0627\u062a \u06a9\u06cc \u062a\u0639\u0631\u06cc\u0641\u06cc\u06ba"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"estimated-reading-time",children:"Estimated Reading Time"}),"\n",(0,s.jsxs)(e.p,{children:["\u06cc\u06c1 \u0645\u0627\u0688\u06cc\u0648\u0644 ",(0,s.jsx)(e.strong,{children:"1.5-2.5 \u06af\u06be\u0646\u0679\u06d2"})," \u0645\u06cc\u06ba \u0645\u06a9\u0645\u0644 \u06a9\u0631\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0688\u06cc\u0632\u0627\u0626\u0646 \u06a9\u06cc\u0627 \u06af\u06cc\u0627 \u06c1\u06d2 average reader \u06a9\u06d2 \u0644\u06cc\u06d2\u060c capstone project \u0634\u0627\u0645\u0644 \u06a9\u0631\u062a\u06d2 \u06c1\u0648\u0626\u06d2\u06d4"]}),"\n",(0,s.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.a,{href:"/ur/modules/module-4-vision-language-action/introduction",children:"\u062a\u0639\u0627\u0631\u0641"})," \u0633\u06d2 \u0634\u0631\u0648\u0639 \u06a9\u0631\u06cc\u06ba \u062a\u0627\u06a9\u06c1 learning objectives \u0627\u0648\u0631 module structure \u0633\u0645\u062c\u06be\u06cc\u06ba\u060c \u067e\u06be\u0631 ",(0,s.jsx)(e.a,{href:"/ur/modules/module-4-vision-language-action/llm-robotics-convergence",children:"LLM-Robotics Convergence"})," \u067e\u0631 \u062c\u0627\u0626\u06cc\u06ba VLA systems \u06a9\u06d2 foundational concepts \u0633\u06cc\u06a9\u06be\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2\u06d4"]})]})}function d(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(u,{...n})}):u(n)}}}]);