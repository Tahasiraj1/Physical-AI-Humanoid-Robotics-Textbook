<!doctype html>
<html lang="en-US" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-modules/module-4-vision-language-action/capstone-project" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Capstone Project - The Autonomous Humanoid | Physical AI Humanoid Robotics Textbook</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://Tahasiraj1.github.io/Physical-AI-Humanoid-Robotics-Textbook/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://Tahasiraj1.github.io/Physical-AI-Humanoid-Robotics-Textbook/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://Tahasiraj1.github.io/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/capstone-project"><meta data-rh="true" property="og:locale" content="en_US"><meta data-rh="true" property="og:locale:alternate" content="ur"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Capstone Project - The Autonomous Humanoid | Physical AI Humanoid Robotics Textbook"><meta data-rh="true" name="description" content="Complete VLA pipeline demonstration showing how a simulated humanoid robot receives voice commands, plans paths, navigates obstacles, identifies objects, and manipulates them."><meta data-rh="true" property="og:description" content="Complete VLA pipeline demonstration showing how a simulated humanoid robot receives voice commands, plans paths, navigates obstacles, identifies objects, and manipulates them."><link data-rh="true" rel="icon" href="/Physical-AI-Humanoid-Robotics-Textbook/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://Tahasiraj1.github.io/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/capstone-project"><link data-rh="true" rel="alternate" href="https://Tahasiraj1.github.io/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/capstone-project" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://Tahasiraj1.github.io/Physical-AI-Humanoid-Robotics-Textbook/ur/modules/module-4-vision-language-action/capstone-project" hreflang="ur"><link data-rh="true" rel="alternate" href="https://Tahasiraj1.github.io/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/capstone-project" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Capstone Project - The Autonomous Humanoid","item":"https://Tahasiraj1.github.io/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/capstone-project"}]}</script><link rel="stylesheet" href="/Physical-AI-Humanoid-Robotics-Textbook/assets/css/styles.70de742d.css">
<script src="/Physical-AI-Humanoid-Robotics-Textbook/assets/js/runtime~main.588ab14b.js" defer="defer"></script>
<script src="/Physical-AI-Humanoid-Robotics-Textbook/assets/js/main.83714e95.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/Physical-AI-Humanoid-Robotics-Textbook/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Physical-AI-Humanoid-Robotics-Textbook/"><div class="navbar__logo"><img src="/Physical-AI-Humanoid-Robotics-Textbook/img/logo.svg" alt="Physical AI Humanoid Robotics Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Physical-AI-Humanoid-Robotics-Textbook/img/logo.svg" alt="Physical AI Humanoid Robotics Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/Physical-AI-Humanoid-Robotics-Textbook/intro">Textbook</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/capstone-project" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en-US">English</a></li><li><a href="/Physical-AI-Humanoid-Robotics-Textbook/ur/modules/module-4-vision-language-action/capstone-project" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="ur">اردو</a></li></ul></div><a class="navbar__item navbar__link" href="/Physical-AI-Humanoid-Robotics-Textbook/dashboard">Dashboard</a><a class="navbar__item navbar__link" href="/Physical-AI-Humanoid-Robotics-Textbook/signin">Sign In</a><a class="navbar__item navbar__link" href="/Physical-AI-Humanoid-Robotics-Textbook/signup">Sign Up</a><a href="https://github.com/Tahasiraj1/Physical-AI-Humanoid-Robotics-Textbook" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Physical-AI-Humanoid-Robotics-Textbook/intro"><span title="Welcome to the Physical AI Humanoid Robotics Textbook" class="linkLabel_WmDU">Welcome to the Physical AI Humanoid Robotics Textbook</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-1-ros2-nervous-system"><span title="Modules" class="categoryLinkLabel_W154">Modules</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-1-ros2-nervous-system"><span title="Module 1: The Robotic Nervous System (ROS 2)" class="categoryLinkLabel_W154">Module 1: The Robotic Nervous System (ROS 2)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-2-digital-twins-simulation"><span title="Module 2: Digital Twins - Simulation &amp; Sensors" class="categoryLinkLabel_W154">Module 2: Digital Twins - Simulation &amp; Sensors</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain"><span title="Module 3: The AI-Robot Brain (NVIDIA Isaac™)" class="categoryLinkLabel_W154">Module 3: The AI-Robot Brain (NVIDIA Isaac™)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action"><span title="Module 4: Vision-Language-Action (VLA)" class="categoryLinkLabel_W154">Module 4: Vision-Language-Action (VLA)</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action"><span title="Module 4 - Vision-Language-Action (VLA)" class="linkLabel_WmDU">Module 4 - Vision-Language-Action (VLA)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/introduction"><span title="Introduction - Vision-Language-Action (VLA) Systems" class="linkLabel_WmDU">Introduction - Vision-Language-Action (VLA) Systems</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/llm-robotics-convergence"><span title="LLM-Robotics Convergence" class="linkLabel_WmDU">LLM-Robotics Convergence</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/voice-to-action"><span title="Voice-to-Action Using OpenAI Whisper" class="linkLabel_WmDU">Voice-to-Action Using OpenAI Whisper</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/cognitive-planning"><span title="Cognitive Planning with LLMs" class="linkLabel_WmDU">Cognitive Planning with LLMs</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/safety-validation"><span title="Safety &amp; Validation of LLM-Generated Plans" class="linkLabel_WmDU">Safety &amp; Validation of LLM-Generated Plans</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/capstone-project"><span title="Capstone Project - The Autonomous Humanoid" class="linkLabel_WmDU">Capstone Project - The Autonomous Humanoid</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/module-integration"><span title="Module Integration - Connecting VLA to Previous Modules" class="linkLabel_WmDU">Module Integration - Connecting VLA to Previous Modules</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/glossary"><span title="Glossary - Key Terminology" class="linkLabel_WmDU">Glossary - Key Terminology</span></a></li></ul></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Physical-AI-Humanoid-Robotics-Textbook/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Modules</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module 4: Vision-Language-Action (VLA)</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Capstone Project - The Autonomous Humanoid</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Capstone Project: The Autonomous Humanoid</h1></header>
<p>This capstone project demonstrates the complete Vision-Language-Action (VLA) pipeline in action. You&#x27;ll see how a simulated humanoid robot receives a voice command, uses cognitive planning to generate a path, navigates obstacles using perception, identifies objects using computer vision, and manipulates them—all integrated into a cohesive autonomous behavior.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="project-overview">Project Overview<a href="#project-overview" class="hash-link" aria-label="Direct link to Project Overview" title="Direct link to Project Overview" translate="no">​</a></h2>
<p>The capstone project integrates all VLA concepts into a single demonstration:</p>
<ul>
<li class=""><strong>Voice input</strong>: A spoken command initiates the autonomous behavior</li>
<li class=""><strong>Cognitive planning</strong>: Natural language is translated into an action plan</li>
<li class=""><strong>Path planning</strong>: A navigation path is generated to reach the goal</li>
<li class=""><strong>Obstacle navigation</strong>: The robot navigates around obstacles using perception</li>
<li class=""><strong>Object identification</strong>: Computer vision identifies target objects</li>
<li class=""><strong>Object manipulation</strong>: The robot grasps and manipulates objects</li>
</ul>
<p>This project shows how voice-to-action, cognitive planning, perception, navigation, and manipulation work together in a complete VLA system.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-complete-vla-pipeline">The Complete VLA Pipeline<a href="#the-complete-vla-pipeline" class="hash-link" aria-label="Direct link to The Complete VLA Pipeline" title="Direct link to The Complete VLA Pipeline" translate="no">​</a></h2>
<p>The capstone demonstrates the end-to-end flow:</p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Voice Command → Speech Recognition → Cognitive Planning → </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Path Planning → Obstacle Navigation → Object Identification → </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Object Manipulation → Task Completion</span><br></span></code></pre></div></div>
<p>Each stage builds upon the previous, creating a seamless autonomous behavior.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-by-step-flow">Step-by-Step Flow<a href="#step-by-step-flow" class="hash-link" aria-label="Direct link to Step-by-Step Flow" title="Direct link to Step-by-Step Flow" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-1-voice-command">Step 1: Voice Command<a href="#step-1-voice-command" class="hash-link" aria-label="Direct link to Step 1: Voice Command" title="Direct link to Step 1: Voice Command" translate="no">​</a></h3>
<p>The user speaks a command: <strong>&quot;Pick up the red cup from the table&quot;</strong></p>
<ul>
<li class=""><strong>Audio capture</strong>: Microphones capture the spoken command</li>
<li class=""><strong>Speech recognition</strong>: OpenAI Whisper transcribes speech to text</li>
<li class=""><strong>Text output</strong>: &quot;Pick up the red cup from the table&quot;</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-2-cognitive-planning">Step 2: Cognitive Planning<a href="#step-2-cognitive-planning" class="hash-link" aria-label="Direct link to Step 2: Cognitive Planning" title="Direct link to Step 2: Cognitive Planning" translate="no">​</a></h3>
<p>The transcribed text is processed by cognitive planning:</p>
<ul>
<li class=""><strong>Intent understanding</strong>: The robot understands it needs to pick up a specific object</li>
<li class=""><strong>Goal decomposition</strong>: The task is broken into sub-goals:<!-- -->
<ol>
<li class="">Navigate to the table</li>
<li class="">Identify the red cup</li>
<li class="">Pick up the cup</li>
<li class="">Verify successful grasp</li>
</ol>
</li>
<li class=""><strong>Action sequence generation</strong>: ROS 2 actions are generated for each sub-goal</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-3-path-planning">Step 3: Path Planning<a href="#step-3-path-planning" class="hash-link" aria-label="Direct link to Step 3: Path Planning" title="Direct link to Step 3: Path Planning" translate="no">​</a></h3>
<p>The cognitive plan includes navigation to the table:</p>
<ul>
<li class=""><strong>Target location</strong>: The table location is identified</li>
<li class=""><strong>Path generation</strong>: A path is planned from current position to table</li>
<li class=""><strong>Obstacle consideration</strong>: Known obstacles are considered in path planning</li>
<li class=""><strong>Path validation</strong>: The path is checked for feasibility</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-4-obstacle-navigation">Step 4: Obstacle Navigation<a href="#step-4-obstacle-navigation" class="hash-link" aria-label="Direct link to Step 4: Obstacle Navigation" title="Direct link to Step 4: Obstacle Navigation" translate="no">​</a></h3>
<p>The robot navigates to the table:</p>
<ul>
<li class=""><strong>Perception</strong>: Sensors detect obstacles in the environment</li>
<li class=""><strong>Path adjustment</strong>: The path is adjusted to avoid obstacles</li>
<li class=""><strong>Navigation execution</strong>: ROS 2 navigation actions move the robot</li>
<li class=""><strong>Progress monitoring</strong>: Navigation progress is monitored and adjusted</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-5-object-identification">Step 5: Object Identification<a href="#step-5-object-identification" class="hash-link" aria-label="Direct link to Step 5: Object Identification" title="Direct link to Step 5: Object Identification" translate="no">​</a></h3>
<p>At the table, computer vision identifies the target:</p>
<ul>
<li class=""><strong>Visual perception</strong>: Cameras capture images of the table</li>
<li class=""><strong>Object detection</strong>: Computer vision detects objects on the table</li>
<li class=""><strong>Object classification</strong>: Objects are classified (cup, bottle, etc.)</li>
<li class=""><strong>Target selection</strong>: The red cup is identified and selected</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-6-object-manipulation">Step 6: Object Manipulation<a href="#step-6-object-manipulation" class="hash-link" aria-label="Direct link to Step 6: Object Manipulation" title="Direct link to Step 6: Object Manipulation" translate="no">​</a></h3>
<p>The robot manipulates the identified object:</p>
<ul>
<li class=""><strong>Grasp planning</strong>: A grasp pose is planned for the cup</li>
<li class=""><strong>Arm movement</strong>: The robot&#x27;s arm moves to the grasp pose</li>
<li class=""><strong>Grasp execution</strong>: The robot grasps the cup</li>
<li class=""><strong>Verification</strong>: Successful grasp is verified</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="integration-of-vla-components">Integration of VLA Components<a href="#integration-of-vla-components" class="hash-link" aria-label="Direct link to Integration of VLA Components" title="Direct link to Integration of VLA Components" translate="no">​</a></h2>
<p>This capstone demonstrates how all VLA components integrate:</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="voice-input-integration">Voice Input Integration<a href="#voice-input-integration" class="hash-link" aria-label="Direct link to Voice Input Integration" title="Direct link to Voice Input Integration" translate="no">​</a></h3>
<p>Voice commands initiate the entire pipeline:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Whisper Integration Pattern in Capstone Context</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># This demonstrates how voice input initiates the capstone project</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> whisper</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> rclpy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> rclpy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">node </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> std_msgs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">msg </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> String</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">CapstoneVoiceInput</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">Node</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    Voice input component for capstone project.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    Demonstrates Whisper integration in complete VLA pipeline.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;capstone_voice_input&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Initialize Whisper (conceptual pattern)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">whisper_model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> whisper</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">load_model</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;base&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Publisher for sending commands to cognitive planning</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">command_publisher </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">create_publisher</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            String</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token string" style="color:#e3116c">&#x27;voice_command&#x27;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token number" style="color:#36acaa">10</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">process_voice_command</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> audio_data</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        Process voice command and publish to cognitive planning.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        This initiates the complete VLA pipeline.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Transcribe audio to text using Whisper</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        result </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">whisper_model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">transcribe</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">audio_data</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        command_text </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> result</span><span class="token punctuation" style="color:#393A34">[</span><span class="token string" style="color:#e3116c">&quot;text&quot;</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Publish command to cognitive planning system</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        msg </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> String</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        msg</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">data </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> command_text</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">command_publisher</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">publish</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">msg</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get_logger</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">info</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&#x27;Voice command received: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">command_text</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> command_text</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="cognitive-planning-integration">Cognitive Planning Integration<a href="#cognitive-planning-integration" class="hash-link" aria-label="Direct link to Cognitive Planning Integration" title="Direct link to Cognitive Planning Integration" translate="no">​</a></h3>
<p>Cognitive planning translates commands to action sequences:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># LLM Cognitive Planning Integration Pattern in Capstone Context</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># This demonstrates how cognitive planning generates action sequences</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">CapstoneCognitivePlanner</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    Cognitive planning component for capstone project.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    Demonstrates LLM integration in complete VLA pipeline.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> llm_client</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">llm_client </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> llm_client</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">plan_capstone_task</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> voice_command</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> robot_context</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        Generate action plan for capstone task.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        This demonstrates cognitive planning in complete VLA pipeline.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Create planning prompt</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        prompt </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string-interpolation string" style="color:#e3116c">f&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        Translate this voice command into a robot action plan:</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        Command: &quot;</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">voice_command</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        Robot context: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">robot_context</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c"></span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        Generate a sequence of actions:</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        1. Navigation to target location</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        2. Object identification</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        3. Object manipulation</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        Output the action sequence in ROS 2 action format.</span><br></span><span class="token-line" style="color:#393A34"><span class="token string-interpolation string" style="color:#e3116c">        &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Generate plan using LLM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        response </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">llm_client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">generate</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">prompt</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Parse response into action sequence</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        action_sequence </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">parse_plan</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">response</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> action_sequence</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">parse_plan</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> llm_response</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        Parse LLM response into ROS 2 action sequence.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        This demonstrates how cognitive plans become executable actions.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Parse structured response</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Extract navigation, perception, and manipulation actions</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        actions </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">[</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># ... parsing logic ...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">return</span><span class="token plain"> actions</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="ros-2-action-generation-integration">ROS 2 Action Generation Integration<a href="#ros-2-action-generation-integration" class="hash-link" aria-label="Direct link to ROS 2 Action Generation Integration" title="Direct link to ROS 2 Action Generation Integration" translate="no">​</a></h3>
<p>ROS 2 actions execute the cognitive plan:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># ROS 2 Action Generation Integration Pattern in Capstone Context</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># This demonstrates how cognitive plans become ROS 2 actions</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> rclpy</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">action </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> ActionClient</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> navigation_msgs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">action </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> NavigateToPose</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> manipulation_msgs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">action </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> PickPlace</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> perception_msgs</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">action </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> DetectObjects</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">class</span><span class="token plain"> </span><span class="token class-name">CapstoneActionExecutor</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">Node</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    Action execution component for capstone project.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    Demonstrates ROS 2 action generation in complete VLA pipeline.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">    &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token builtin">super</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;capstone_action_executor&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Action clients for different capabilities</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nav_client </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ActionClient</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> NavigateToPose</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;navigate_to_pose&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">manip_client </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ActionClient</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> PickPlace</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;pick_place&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">perception_client </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> ActionClient</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> DetectObjects</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&#x27;detect_objects&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">execute_capstone_plan</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> cognitive_plan</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        Execute complete capstone plan.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        This demonstrates ROS 2 action execution in complete VLA pipeline.</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">        &quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Execute navigation actions</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> nav_action </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> cognitive_plan</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">navigation_actions</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">execute_navigation</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">nav_action</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Execute perception actions</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> perception_action </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> cognitive_plan</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">perception_actions</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">execute_perception</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">perception_action</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Execute manipulation actions</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> manip_action </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> cognitive_plan</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">manipulation_actions</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">execute_manipulation</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">manip_action</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">execute_navigation</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> action</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;Execute navigation action.&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        goal </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> NavigateToPose</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Goal</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        goal</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pose </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> action</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">target_pose</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">nav_client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">send_goal_async</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">goal</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">def</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">execute_manipulation</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> action</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;Execute manipulation action.&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        goal </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> PickPlace</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">Goal</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        goal</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">object_id </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> action</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">object_id</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        goal</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pick_pose </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> action</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">pick_pose</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">manip_client</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">send_goal_async</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">goal</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="cross-references-to-previous-modules">Cross-References to Previous Modules<a href="#cross-references-to-previous-modules" class="hash-link" aria-label="Direct link to Cross-References to Previous Modules" title="Direct link to Cross-References to Previous Modules" translate="no">​</a></h2>
<p>This capstone project builds upon concepts from previous modules:</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="module-2-simulation">Module 2: Simulation<a href="#module-2-simulation" class="hash-link" aria-label="Direct link to Module 2: Simulation" title="Direct link to Module 2: Simulation" translate="no">​</a></h3>
<p>The capstone project runs in a simulated environment, demonstrating how <a class="" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-2-digital-twins-simulation/simulation-fundamentals">Module 2: Digital Twins - Simulation &amp; Sensors</a> enables safe testing and development of VLA systems. Simulation allows:</p>
<ul>
<li class=""><strong>Safe testing</strong>: Testing VLA systems without physical risk</li>
<li class=""><strong>Rapid iteration</strong>: Quickly testing different scenarios</li>
<li class=""><strong>Environment control</strong>: Creating consistent test conditions</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="module-3-perception-and-navigation">Module 3: Perception and Navigation<a href="#module-3-perception-and-navigation" class="hash-link" aria-label="Direct link to Module 3: Perception and Navigation" title="Direct link to Module 3: Perception and Navigation" translate="no">​</a></h3>
<p>The capstone project uses perception and navigation capabilities from <a class="" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-3-ai-robot-brain/nav2-path-planning">Module 3: The AI-Robot Brain (NVIDIA Isaac™)</a>, including:</p>
<ul>
<li class=""><strong>Computer vision</strong>: Object identification and classification</li>
<li class=""><strong>Path planning</strong>: Navigation path generation</li>
<li class=""><strong>Obstacle avoidance</strong>: Dynamic obstacle navigation</li>
<li class=""><strong>Sensor integration</strong>: Using cameras and sensors for perception</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="complete-integration-flow-diagram">Complete Integration Flow Diagram<a href="#complete-integration-flow-diagram" class="hash-link" aria-label="Direct link to Complete Integration Flow Diagram" title="Direct link to Complete Integration Flow Diagram" translate="no">​</a></h2>
<p>The following diagram illustrates the complete capstone project flow:</p>
<div class="language-mermaid codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-mermaid codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">flowchart TD</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    A[Voice Command] --&gt; B[Whisper Transcription]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    B --&gt; C[Cognitive Planning]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    C --&gt; D[Action Sequence]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    D --&gt; E[Path Planning]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    E --&gt; F[Navigation Actions]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    F --&gt; G[Obstacle Navigation]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    G --&gt; H[Object Detection]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    H --&gt; I[Object Identification]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    I --&gt; J[Grasp Planning]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    J --&gt; K[Manipulation Actions]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    K --&gt; L[Task Completion]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    style A fill:#e1f5ff</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    style C fill:#fff4e1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    style E fill:#e8f5e9</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    style L fill:#fce4ec</span><br></span></code></pre></div></div>
<p>This diagram shows how all VLA components integrate in the complete autonomous behavior.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary" translate="no">​</a></h2>
<p>The capstone project demonstrates the complete VLA pipeline, integrating voice input, cognitive planning, path planning, obstacle navigation, object identification, and manipulation into a cohesive autonomous behavior. This project shows how all VLA concepts work together, from a simple voice command to complex robot behavior. Understanding this integration is essential for comprehending how VLA systems enable natural language robot control.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="next-steps">Next Steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps" translate="no">​</a></h2>
<p>Now that you understand the complete VLA pipeline through the capstone project, proceed to <a class="" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/module-integration">Module Integration</a> to learn how VLA concepts connect to and build upon previous modules.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-tags-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/Physical-AI-Humanoid-Robotics-Textbook/tags/vla">vla</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/Physical-AI-Humanoid-Robotics-Textbook/tags/capstone">capstone</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/Physical-AI-Humanoid-Robotics-Textbook/tags/autonomous-robot">autonomous-robot</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/Physical-AI-Humanoid-Robotics-Textbook/tags/voice-to-action">voice-to-action</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/Physical-AI-Humanoid-Robotics-Textbook/tags/cognitive-planning">cognitive-planning</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/Physical-AI-Humanoid-Robotics-Textbook/tags/navigation">navigation</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/Physical-AI-Humanoid-Robotics-Textbook/tags/manipulation">manipulation</a></li><li class="tag_QGVx"><a rel="tag" class="tag_zVej tagRegular_sFm0" href="/Physical-AI-Humanoid-Robotics-Textbook/tags/humanoid-robotics">humanoid-robotics</a></li></ul></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/safety-validation"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Safety &amp; Validation of LLM-Generated Plans</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-4-vision-language-action/module-integration"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Module Integration - Connecting VLA to Previous Modules</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#project-overview" class="table-of-contents__link toc-highlight">Project Overview</a></li><li><a href="#the-complete-vla-pipeline" class="table-of-contents__link toc-highlight">The Complete VLA Pipeline</a></li><li><a href="#step-by-step-flow" class="table-of-contents__link toc-highlight">Step-by-Step Flow</a><ul><li><a href="#step-1-voice-command" class="table-of-contents__link toc-highlight">Step 1: Voice Command</a></li><li><a href="#step-2-cognitive-planning" class="table-of-contents__link toc-highlight">Step 2: Cognitive Planning</a></li><li><a href="#step-3-path-planning" class="table-of-contents__link toc-highlight">Step 3: Path Planning</a></li><li><a href="#step-4-obstacle-navigation" class="table-of-contents__link toc-highlight">Step 4: Obstacle Navigation</a></li><li><a href="#step-5-object-identification" class="table-of-contents__link toc-highlight">Step 5: Object Identification</a></li><li><a href="#step-6-object-manipulation" class="table-of-contents__link toc-highlight">Step 6: Object Manipulation</a></li></ul></li><li><a href="#integration-of-vla-components" class="table-of-contents__link toc-highlight">Integration of VLA Components</a><ul><li><a href="#voice-input-integration" class="table-of-contents__link toc-highlight">Voice Input Integration</a></li><li><a href="#cognitive-planning-integration" class="table-of-contents__link toc-highlight">Cognitive Planning Integration</a></li><li><a href="#ros-2-action-generation-integration" class="table-of-contents__link toc-highlight">ROS 2 Action Generation Integration</a></li></ul></li><li><a href="#cross-references-to-previous-modules" class="table-of-contents__link toc-highlight">Cross-References to Previous Modules</a><ul><li><a href="#module-2-simulation" class="table-of-contents__link toc-highlight">Module 2: Simulation</a></li><li><a href="#module-3-perception-and-navigation" class="table-of-contents__link toc-highlight">Module 3: Perception and Navigation</a></li></ul></li><li><a href="#complete-integration-flow-diagram" class="table-of-contents__link toc-highlight">Complete Integration Flow Diagram</a></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next Steps</a></li></ul></div></div></div><div class="personalizationSection_jgH2"><div class="personalizationHeader_PJO3"><h2>Personalize This Section</h2></div><div class="personalizationActions_MzyH"><div class="actionItem_qUQm"><a class="bookmarkButton__XtL" href="/Physical-AI-Humanoid-Robotics-Textbook/signin">⭐ Bookmark</a></div></div><div class="personalizationContent_YtC3"><div class="contentSection_sV5q"><div class="noteEditor_ZMHQ"><p>Please <a href="/Physical-AI-Humanoid-Robotics-Textbook/signin">sign in</a> to add notes.</p></div></div><div class="contentSection_sV5q"><div>Loading comments...</div></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Modules</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Physical-AI-Humanoid-Robotics-Textbook/modules/module-1-ros2-nervous-system">Module 1: ROS 2 Nervous System</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Resources</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/Tahasiraj1/Physical-AI-Humanoid-Robotics-Textbook" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Physical AI Humanoid Robotics Textbook. Built with Docusaurus.</div></div></div></footer><div class="chatWidgetContainer_wdR7"><button class="chatButton_gSQt" aria-label="Open chat widget" aria-expanded="false" type="button"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" aria-hidden="true"><path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></button></div></div>
</body>
</html>